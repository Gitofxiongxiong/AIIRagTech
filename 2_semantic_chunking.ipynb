{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Chunking 简介\n",
    "文本分块是检索增强生成（RAG）中的一个重要步骤，在RAG中，不同于固定长度的分块，为了提高检索精度，Semantic Chunking是根据语义信息将文本分割成更合适的语义块\n",
    "\n",
    "## breakpoints查找方法\n",
    "*   **百分位数 (Percentile)**：找出所有相似度差异的第 X 个百分位数，并在差异下降幅度大于此值的区块进行分割。\n",
    "*   **标准差 (Standard Deviation)**：在相似度下降幅度超过平均值以下 X 个标准差的区块进行分割。\n",
    "*   **四分位距 (Interquartile Range, IQR)**：使用四分位距（Q3 - Q1，即第三四分位数减去第一四分位数）来确定分割点。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "导入必要的库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymupdf\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "提取pdf中的文本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Understanding Artificial Intelligence \n",
      "Chapter 1: Introduction to Artificial Intelligence \n",
      "Artificial intelligence (AI) refers to the ability of a digital computer or computer-controlled robot \n",
      "to perform tasks commonly associated with intelligent beings. The term is frequently applied to \n",
      "the project of developing systems endowed with the intellectual processes characteristic of \n",
      "humans, such as the ability to reason, discover meaning, generalize, or learn from past \n",
      "experience. Over the past f\n"
     ]
    }
   ],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"\n",
    "    提取PDF文件中的文本并打印前`num_chars`个字符。\n",
    "\n",
    "    参数：\n",
    "    pdf_path (str): PDF文件的路径。\n",
    "\n",
    "    返回：\n",
    "    str: 从PDF中提取的文本。\n",
    "\n",
    "    \"\"\"\n",
    "    # 打开PDF文件\n",
    "    mypdf = pymupdf.open(pdf_path)\n",
    "    all_text = \"\"  # 初始化一个空字符串来存储提取的文本\n",
    "\n",
    "    # 迭代PDF中的每个页面\n",
    "    for page_num in range(mypdf.page_count):\n",
    "        page = mypdf[page_num]  # 获取页面\n",
    "        text = page.get_text(\"text\")  # 从页面中提取文本\n",
    "        all_text += text  # 将提取的文本附加到all_text字符串\n",
    "\n",
    "    return all_text  # 返回提取的文本\n",
    "\n",
    "pdf_path = \"data/AI_Information.pdf\"\n",
    "\n",
    "\n",
    "extracted_text = extract_text_from_pdf(pdf_path)\n",
    "\n",
    "print(extracted_text[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "配置client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = openai.OpenAI(\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\"),  # 如果您没有配置环境变量，请在此处用您的API Key进行替换\n",
    "    base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\"  # 百炼服务的base_url\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建Sentence-Level Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 1, size: 10\n",
      "Processing batch 2, size: 10\n",
      "Processing batch 3, size: 10\n",
      "Processing batch 4, size: 10\n",
      "Processing batch 5, size: 10\n",
      "Processing batch 6, size: 10\n",
      "Processing batch 7, size: 10\n",
      "Processing batch 8, size: 10\n",
      "Processing batch 9, size: 10\n",
      "Processing batch 10, size: 10\n",
      "Processing batch 11, size: 10\n",
      "Processing batch 12, size: 10\n",
      "Processing batch 13, size: 10\n",
      "Processing batch 14, size: 10\n",
      "Processing batch 15, size: 10\n",
      "Processing batch 16, size: 10\n",
      "Processing batch 17, size: 10\n",
      "Processing batch 18, size: 10\n",
      "Processing batch 19, size: 10\n",
      "Processing batch 20, size: 10\n",
      "Processing batch 21, size: 10\n",
      "Processing batch 22, size: 10\n",
      "Processing batch 23, size: 10\n",
      "Processing batch 24, size: 10\n",
      "Processing batch 25, size: 10\n",
      "Processing batch 26, size: 8\n",
      "Generated 258 sentence embeddings.\n"
     ]
    }
   ],
   "source": [
    "def create_embeddings_in_batches(text_chunks, model=\"text-embedding-v3\", batch_size_limit=10): # 我改成了官方模型名，你可以换回 \"text-embedding-v3\"\n",
    "    \"\"\"\n",
    "    调用 OpenAI 的 Embedding API 来创建文本列表的嵌入向量，处理批处理大小限制。\n",
    "\n",
    "    参数:\n",
    "    text_chunks (List[str]): 需要创建嵌入的文本字符串列表。\n",
    "    model (str): 使用的嵌入模型。\n",
    "    batch_size_limit (int): API 允许的最大批处理大小。根据错误信息，这里是10。\n",
    "\n",
    "    返回:\n",
    "    List[List[float]]: 所有文本的嵌入向量列表。\n",
    "    \"\"\"\n",
    "    all_embeddings = []\n",
    "    if not text_chunks:\n",
    "        return []\n",
    "\n",
    "    if not isinstance(text_chunks, list): # 确保输入是列表\n",
    "        text_chunks = [text_chunks]\n",
    "\n",
    "    for i in range(0, len(text_chunks), batch_size_limit):\n",
    "        batch = text_chunks[i:i + batch_size_limit]\n",
    "        try:\n",
    "            print(f\"Processing batch {i//batch_size_limit + 1}, size: {len(batch)}\")\n",
    "            response = client.embeddings.create(\n",
    "                input=batch,\n",
    "                model=model,\n",
    "                encoding_format=\"float\"\n",
    "            )\n",
    "            # 从响应中提取该批次的嵌入向量\n",
    "            batch_embeddings = [item.embedding for item in response.data]\n",
    "            all_embeddings.extend(batch_embeddings)\n",
    "\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing batch starting with chunk: '{batch[0][:50]}...'\")\n",
    "            print(f\"API Error: {e}\")\n",
    "\n",
    "            raise e \n",
    "\n",
    "    return all_embeddings\n",
    "sentences = extracted_text.split(\". \")\n",
    "embeddings = create_embeddings_in_batches(sentences)\n",
    "print(f\"Generated {len(embeddings)} sentence embeddings.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "计算余弦相似度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[np.float64(0.6013919200673946), np.float64(0.523915742179365), np.float64(0.5992367054894817), np.float64(0.5681652381873313), np.float64(0.6467175552026007), np.float64(0.6481387924480176), np.float64(0.4759750128504935), np.float64(0.5732421982853909), np.float64(0.5287207011143132), np.float64(0.697532561722569), np.float64(0.733507284579057), np.float64(0.43262204394390386), np.float64(0.28890282858367256), np.float64(0.6558550595232097), np.float64(0.5844338512977106), np.float64(0.6107934390675273), np.float64(0.5436887130330174), np.float64(0.4622488446977352), np.float64(0.5016057216882477), np.float64(0.44435236530646904), np.float64(0.7079794035709691), np.float64(0.5919520924416597), np.float64(0.5037783024518371), np.float64(0.47439976357390534), np.float64(0.5013646767771311), np.float64(0.5819812641586012), np.float64(0.6175757205905621), np.float64(0.5956586973274686), np.float64(0.5947336486016098), np.float64(0.6077561880239367), np.float64(0.5509006531578936), np.float64(0.7118642191647473), np.float64(0.4221924439937631), np.float64(0.6245916032200239), np.float64(0.6805212565595029), np.float64(0.5691886661134558), np.float64(0.6970701626537719), np.float64(0.7485633820242882), np.float64(0.5916090928330493), np.float64(0.7356328413066657), np.float64(0.6018580491355883), np.float64(0.7059425711091524), np.float64(0.556347833136573), np.float64(0.7436998992624788), np.float64(0.6449076715311238), np.float64(0.7154825918191071), np.float64(0.635280425088185), np.float64(0.7864537846848756), np.float64(0.5278814350478764), np.float64(0.7008350487490094), np.float64(0.5362706200997891), np.float64(0.7896280677678521), np.float64(0.5143379963821794), np.float64(0.6528654454677145), np.float64(0.744018699088797), np.float64(0.6238205803702123), np.float64(0.5286556327027032), np.float64(0.3932218018557862), np.float64(0.6115473270049071), np.float64(0.3814483826263715), np.float64(0.6008677570877273), np.float64(0.6241010525228932), np.float64(0.5059032885503316), np.float64(0.61589826883475), np.float64(0.7136880319859065), np.float64(0.49076562926706935), np.float64(0.640323377484763), np.float64(0.7169358742212596), np.float64(0.49724078112732983), np.float64(0.619840481257198), np.float64(0.5543011014849998), np.float64(0.7949879197191808), np.float64(0.6139690732032899), np.float64(0.6350968196978554), np.float64(0.6220141103006037), np.float64(0.8184392012431334), np.float64(0.5056072983115727), np.float64(0.5178057594275242), np.float64(0.543009372751632), np.float64(0.42533838160976156), np.float64(0.678027307140732), np.float64(0.5022431885693744), np.float64(0.6388922980715507), np.float64(0.6261338874817545), np.float64(0.697239167029395), np.float64(0.49904940115944346), np.float64(0.5820181689860856), np.float64(0.6626668609956867), np.float64(0.6003090589380794), np.float64(0.7758726883658688), np.float64(0.4651387157954778), np.float64(0.5886458849162002), np.float64(0.5629870343179483), np.float64(0.6779867029689105), np.float64(0.6379187834626803), np.float64(0.6238773397862041), np.float64(0.6260495236401865), np.float64(0.5986489338704574), np.float64(0.49385979086449927), np.float64(0.5885662953010771), np.float64(0.45637394279170623), np.float64(0.6657726072174798), np.float64(0.6193850790562162), np.float64(0.7056933400200206), np.float64(0.5864213183512393), np.float64(0.763569264489512), np.float64(0.5385761016642717), np.float64(0.7513576897031665), np.float64(0.6530119233105826), np.float64(0.7144073102018704), np.float64(0.6171709619343219), np.float64(0.7470077010436954), np.float64(0.5169025240026446), np.float64(0.7071095184216177), np.float64(0.5896300038729887), np.float64(0.605599016167642), np.float64(0.5966330990826549), np.float64(0.6214531428180899), np.float64(0.5938333899469652), np.float64(0.5198736086967377), np.float64(0.3751582554181822), np.float64(0.6337730572759618), np.float64(0.4967855367494858), np.float64(0.6881575329037384), np.float64(0.7323835482560791), np.float64(0.6437279251069847), np.float64(0.48519635473733946), np.float64(0.7301075444261219), np.float64(0.5467479648648762), np.float64(0.7813877730922185), np.float64(0.6089561988598593), np.float64(0.6282117223086706), np.float64(0.5170655025901545), np.float64(0.6779930328574512), np.float64(0.6881600361931777), np.float64(0.7270060987992096), np.float64(0.5442618087742689), np.float64(0.5858376557605938), np.float64(0.590661207282614), np.float64(0.7320510114788985), np.float64(0.6030783448697171), np.float64(0.6457352853977075), np.float64(0.46926257245425396), np.float64(0.6620255276832878), np.float64(0.5759336966575318), np.float64(0.5825320629623812), np.float64(0.6298734070098978), np.float64(0.7026178755094984), np.float64(0.4383809514827157), np.float64(0.6305687743683379), np.float64(0.5644131836914047), np.float64(0.7107328317370282), np.float64(0.5306889022779264), np.float64(0.7958571426170974), np.float64(0.6368899157549189), np.float64(0.570532068543935), np.float64(0.5057233371797993), np.float64(0.7270325778871465), np.float64(0.6064928391013503), np.float64(0.7557545444004888), np.float64(0.6783365479886866), np.float64(0.7337090769965166), np.float64(0.5432267275830805), np.float64(0.6532829444999892), np.float64(0.6979607570951373), np.float64(0.7396658422319784), np.float64(0.5301315061737615), np.float64(0.6230365132959294), np.float64(0.625648895791135), np.float64(0.723405349856962), np.float64(0.5247445191193587), np.float64(0.6035903285788428), np.float64(0.5279024882351463), np.float64(0.7398364484833096), np.float64(0.707540717796883), np.float64(0.6908684713536917), np.float64(0.5513807510304434), np.float64(0.7079123072301734), np.float64(0.6038949062565899), np.float64(0.7617226145129604), np.float64(0.6277504348641311), np.float64(0.7331354689878307), np.float64(0.36471988318128246), np.float64(0.6295345666809852), np.float64(0.504169040375), np.float64(0.7532005421802881), np.float64(0.4736490709639756), np.float64(0.6531654832458702), np.float64(0.5059999517137546), np.float64(0.6395716090692619), np.float64(0.6028101856953172), np.float64(0.6362506791284326), np.float64(0.4667197553458663), np.float64(0.6998315695995112), np.float64(0.6578118792549615), np.float64(0.7002129705516013), np.float64(0.6786030964514926), np.float64(0.7521718774857209), np.float64(0.628716584887098), np.float64(0.7107815936993073), np.float64(0.629125860234372), np.float64(0.6544169058843166), np.float64(0.46395968994270015), np.float64(0.7823622946620655), np.float64(0.6336642865182507), np.float64(0.7677897487873646), np.float64(0.5967599167565497), np.float64(0.7732468773521922), np.float64(0.7533405856762609), np.float64(0.7331354689878307), np.float64(0.5885890224680617), np.float64(0.7752386030164543), np.float64(0.5087908789912782), np.float64(0.6008017462248159), np.float64(0.5076082279808682), np.float64(0.5132958721905843), np.float64(0.5317618730297027), np.float64(0.4082365477528024), np.float64(0.762452958511723), np.float64(0.6533535835458759), np.float64(0.4932793372715312), np.float64(0.6551920605438838), np.float64(0.62482062547266), np.float64(0.6761643642933519), np.float64(0.5244315079979888), np.float64(0.618442686017059), np.float64(0.3953324202947602), np.float64(0.6940582200985242), np.float64(0.47824052020803015), np.float64(0.7436088578482625), np.float64(0.45306399727020963), np.float64(0.6427105922073961), np.float64(0.522369774744648), np.float64(0.7084713021732535), np.float64(0.5742841613897305), np.float64(0.7305712350996212), np.float64(0.721514932041966), np.float64(0.6418921261469532), np.float64(0.6067392674627952), np.float64(0.6784312161671385), np.float64(0.5397242944348492), np.float64(0.6119533602282224), np.float64(0.5907292609119166), np.float64(0.5846351755273441), np.float64(0.4020812915638188), np.float64(0.696436711392872), np.float64(0.6137309737481101), np.float64(0.49409439659056953), np.float64(0.4477939542370692), np.float64(0.6265101781586455), np.float64(0.5746219745780863), np.float64(0.5910843672216545), np.float64(0.49507304652958917), np.float64(0.7074827449062405), np.float64(0.6934401377198463), np.float64(0.7352757007188906), np.float64(0.5268627003789554)]\n"
     ]
    }
   ],
   "source": [
    "def cosine_similarity(vec1, vec2):\n",
    "    \"\"\"\n",
    "    计算两个向量之间的余弦相似度。\n",
    "\n",
    "    参数:\n",
    "    vec1 (numpy.ndarray): 第一个向量。\n",
    "    vec2 (numpy.ndarray): 第二个向量。\n",
    "\n",
    "    返回:\n",
    "    float: 余弦相似度。\n",
    "\n",
    "    \"\"\"\n",
    "    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
    "\n",
    "# Compute similarity between consecutive sentences\n",
    "similarities = [cosine_similarity(embeddings[i], embeddings[i + 1]) for i in range(len(embeddings) - 1)]\n",
    "print(similarities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根据语义分块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_breakpoints(similarities, method=\"percentile\", threshold=90):\n",
    "    \"\"\"\n",
    "    计算相似度列表中的断点。\n",
    "\n",
    "    参数:\n",
    "    similarities (List[float]): 相似度列表。\n",
    "    method (str): 用于确定断点的方法，可选值为 \"percentile\", \"standard_deviation\", \"interquartile\"。\n",
    "    threshold (float): 用于确定断点的阈值。\n",
    "\n",
    "    返回:\n",
    "    List[int]: 相似度列表中的断点索引。\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    if method == \"percentile\":\n",
    "        threshold_value = np.percentile(similarities, threshold)\n",
    "    elif method == \"standard_deviation\":\n",
    "        \n",
    "        mean = np.mean(similarities)\n",
    "        std_dev = np.std(similarities)\n",
    "        \n",
    "        threshold_value = mean - (threshold * std_dev)\n",
    "    elif method == \"interquartile\":\n",
    "        \n",
    "        q1, q3 = np.percentile(similarities, [25, 75])\n",
    "        \n",
    "        threshold_value = q1 - 1.5 * (q3 - q1)\n",
    "    else:\n",
    "        \n",
    "        raise ValueError(\"Invalid method. Choose 'percentile', 'standard_deviation', or 'interquartile'.\")\n",
    "\n",
    "    \n",
    "    return [i for i, sim in enumerate(similarities) if sim < threshold_value]\n",
    "\n",
    "# Compute breakpoints using the percentile method with a threshold of 90\n",
    "breakpoints = compute_breakpoints(similarities, method=\"percentile\", threshold=90)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qwen_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
