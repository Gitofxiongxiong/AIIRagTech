{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "source": [
    "# 命题分块增强 RAG (Proposition Chunking for Enhanced RAG)\n",
    "\n",
    "在这个笔记本中，我实现了命题分块（Proposition Chunking）- 一种先进的技术，将文档分解为原子性的、事实性的陈述，以实现更准确的检索。与传统的按字符数简单分割文本的分块方法不同，命题分块保持了单个事实的语义完整性。\n",
    "\n",
    "命题分块通过以下方式提供更精确的检索：\n",
    "\n",
    "1. 将内容分解为原子性的、自包含的事实\n",
    "2. 创建更小、更细粒度的检索单元\n",
    "3. 实现查询与相关内容之间更精确的匹配\n",
    "4. 过滤掉低质量或不完整的命题\n",
    "\n",
    "让我们构建一个完整的实现，而不依赖 LangChain 或 FAISS。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 设置环境\n",
    "我们首先导入必要的库。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import fitz\n",
    "from openai import OpenAI\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 从 PDF 文件提取文本\n",
    "为了实现 RAG，我们首先需要文本数据源。在这种情况下，我们使用 PyMuPDF 库从 PDF 文件中提取文本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"\n",
    "    从 PDF 文件中提取文本。\n",
    "\n",
    "    参数:\n",
    "    pdf_path (str): PDF 文件的路径。\n",
    "\n",
    "    返回:\n",
    "    str: 从 PDF 中提取的文本。\n",
    "    \"\"\"\n",
    "    # 打开 PDF 文件\n",
    "    mypdf = fitz.open(pdf_path)\n",
    "    all_text = \"\"  # 初始化一个空字符串来存储提取的文本\n",
    "\n",
    "    # 遍历 PDF 中的每一页\n",
    "    for page_num in range(mypdf.page_count):\n",
    "        page = mypdf[page_num]  # 获取页面\n",
    "        text = page.get_text(\"text\")  # 从页面提取文本\n",
    "        all_text += text  # 将提取的文本追加到 all_text 字符串中\n",
    "\n",
    "    return all_text  # 返回提取的文本"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 对提取的文本进行分块\n",
    "一旦我们有了提取的文本，我们将其分成更小的、重叠的块以提高检索准确性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text(text, chunk_size=800, overlap=100):\n",
    "    \"\"\"\n",
    "    将文本分割成重叠的块。\n",
    "    \n",
    "    参数:\n",
    "        text (str): 要分块的输入文本\n",
    "        chunk_size (int): 每个块的字符数大小\n",
    "        overlap (int): 块之间的重叠字符数\n",
    "        \n",
    "    返回:\n",
    "        List[Dict]: 包含文本和元数据的块字典列表\n",
    "    \"\"\"\n",
    "    chunks = []  # 初始化一个空列表来存储块\n",
    "    \n",
    "    # 按指定的块大小和重叠遍历文本\n",
    "    for i in range(0, len(text), chunk_size - overlap):\n",
    "        chunk = text[i:i + chunk_size]  # 提取指定大小的块\n",
    "        if chunk:  # 确保我们不添加空块\n",
    "            chunks.append({\n",
    "                \"text\": chunk,  # 块文本\n",
    "                \"chunk_id\": len(chunks) + 1,  # 块的唯一 ID\n",
    "                \"start_char\": i,  # 块的起始字符索引\n",
    "                \"end_char\": i + len(chunk)  # 块的结束字符索引\n",
    "            })\n",
    "    \n",
    "    print(f\"创建了 {len(chunks)} 个文本块\")  # 打印创建的块数量\n",
    "    return chunks  # 返回块列表"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 设置 OpenAI API 客户端\n",
    "我们初始化 OpenAI 客户端来生成嵌入向量和响应。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用基础 URL 和 API 密钥初始化 OpenAI 客户端\n",
    "client = OpenAI(\n",
    "    base_url=\"https://api.studio.nebius.com/v1/\",\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\")  # 从环境变量中获取 API 密钥\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 简单向量存储实现\n",
    "我们将创建一个基本的向量存储来管理文档块及其嵌入向量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleVectorStore:\n",
    "    \"\"\"\n",
    "    使用 NumPy 的简单向量存储实现。\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        # 初始化列表来存储向量、文本和元数据\n",
    "        self.vectors = []\n",
    "        self.texts = []\n",
    "        self.metadata = []\n",
    "    \n",
    "    def add_item(self, text, embedding, metadata=None):\n",
    "        \"\"\"\n",
    "        向向量存储中添加一个项目。\n",
    "        \n",
    "        参数:\n",
    "            text (str): 文本内容\n",
    "            embedding (List[float]): 嵌入向量\n",
    "            metadata (Dict, optional): 附加元数据\n",
    "        \"\"\"\n",
    "        # 将嵌入向量、文本和元数据追加到各自的列表中\n",
    "        self.vectors.append(np.array(embedding))\n",
    "        self.texts.append(text)\n",
    "        self.metadata.append(metadata or {})\n",
    "    \n",
    "    def add_items(self, texts, embeddings, metadata_list=None):\n",
    "        \"\"\"\n",
    "        向向量存储中添加多个项目。\n",
    "        \n",
    "        参数:\n",
    "            texts (List[str]): 文本内容列表\n",
    "            embeddings (List[List[float]]): 嵌入向量列表\n",
    "            metadata_list (List[Dict], optional): 元数据字典列表\n",
    "        \"\"\"\n",
    "        # 如果没有提供元数据列表，为每个文本创建一个空字典\n",
    "        if metadata_list is None:\n",
    "            metadata_list = [{} for _ in range(len(texts))]\n",
    "        \n",
    "        # 将每个文本、嵌入向量和元数据添加到存储中\n",
    "        for text, embedding, metadata in zip(texts, embeddings, metadata_list):\n",
    "            self.add_item(text, embedding, metadata)\n",
    "    \n",
    "    def similarity_search(self, query_embedding, k=5):\n",
    "        \"\"\"\n",
    "        查找与查询嵌入向量最相似的项目。\n",
    "        \n",
    "        参数:\n",
    "            query_embedding (List[float]): 查询嵌入向量\n",
    "            k (int): 返回结果的数量\n",
    "            \n",
    "        返回:\n",
    "            List[Dict]: 前 k 个最相似的项目\n",
    "        \"\"\"\n",
    "        # 如果存储中没有向量，返回空列表\n",
    "        if not self.vectors:\n",
    "            return []\n",
    "        \n",
    "        # 将查询嵌入向量转换为 numpy 数组\n",
    "        query_vector = np.array(query_embedding)\n",
    "        \n",
    "        # 使用余弦相似度计算相似性\n",
    "        similarities = []\n",
    "        for i, vector in enumerate(self.vectors):\n",
    "            similarity = np.dot(query_vector, vector) / (np.linalg.norm(query_vector) * np.linalg.norm(vector))\n",
    "            similarities.append((i, similarity))\n",
    "        \n",
    "        # 按相似度降序排序\n",
    "        similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        # 收集前 k 个结果\n",
    "        results = []\n",
    "        for i in range(min(k, len(similarities))):\n",
    "            idx, score = similarities[i]\n",
    "            results.append({\n",
    "                \"text\": self.texts[idx],\n",
    "                \"metadata\": self.metadata[idx],\n",
    "                \"similarity\": float(score)  # 转换为 float 以便 JSON 序列化\n",
    "            })\n",
    "        \n",
    "        return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建嵌入向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embeddings(texts, model=\"BAAI/bge-en-icl\"):\n",
    "    \"\"\"\n",
    "    为给定的文本创建嵌入向量。\n",
    "    \n",
    "    参数:\n",
    "        texts (str or List[str]): 输入文本\n",
    "        model (str): 嵌入模型名称\n",
    "        \n",
    "    返回:\n",
    "        List[List[float]]: 嵌入向量\n",
    "    \"\"\"\n",
    "    # 处理字符串和列表输入\n",
    "    input_texts = texts if isinstance(texts, list) else [texts]\n",
    "    \n",
    "    # 如果需要，分批处理（OpenAI API 限制）\n",
    "    batch_size = 100\n",
    "    all_embeddings = []\n",
    "    \n",
    "    # 分批遍历输入文本\n",
    "    for i in range(0, len(input_texts), batch_size):\n",
    "        batch = input_texts[i:i + batch_size]  # 获取当前批次的文本\n",
    "        \n",
    "        # 为当前批次创建嵌入向量\n",
    "        response = client.embeddings.create(\n",
    "            model=model,\n",
    "            input=batch\n",
    "        )\n",
    "        \n",
    "        # 从响应中提取嵌入向量\n",
    "        batch_embeddings = [item.embedding for item in response.data]\n",
    "        all_embeddings.extend(batch_embeddings)  # 将批次嵌入向量添加到列表中\n",
    "    \n",
    "    # 如果输入是单个字符串，只返回第一个嵌入向量\n",
    "    if isinstance(texts, str):\n",
    "        return all_embeddings[0]\n",
    "    \n",
    "    # 否则，返回所有嵌入向量\n",
    "    return all_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 命题生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_propositions(chunk):\n",
    "    \"\"\"\n",
    "    从文本块生成原子性的、自包含的命题。\n",
    "    \n",
    "    参数:\n",
    "        chunk (Dict): 包含内容和元数据的文本块\n",
    "        \n",
    "    返回:\n",
    "        List[str]: 生成的命题列表\n",
    "    \"\"\"\n",
    "    # 系统提示词，指导 AI 如何生成命题\n",
    "    system_prompt = \"\"\"请将以下文本分解为简单的、自包含的命题。\n",
    "    确保每个命题满足以下标准：\n",
    "\n",
    "    1. 表达单一事实：每个命题应该陈述一个具体的事实或声明。\n",
    "    2. 无需上下文即可理解：命题应该是自包含的，意味着无需额外上下文即可理解。\n",
    "    3. 使用全名，不使用代词：避免代词或模糊引用；使用完整的实体名称。\n",
    "    4. 包含相关日期/限定词：如果适用，包含必要的日期、时间和限定词以使事实精确。\n",
    "    5. 包含一个主谓关系：专注于单一主语及其对应的动作或属性，不使用连词或多个从句。\n",
    "\n",
    "    仅输出命题列表，不要任何额外的文本或解释。\"\"\"\n",
    "\n",
    "    # 包含要转换为命题的文本块的用户提示词\n",
    "    user_prompt = f\"要转换为命题的文本：\\n\\n{chunk['text']}\"\n",
    "    \n",
    "    # 从模型生成响应\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"meta-llama/Llama-3.2-3B-Instruct\",  # 使用更强的模型进行准确的命题生成\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ],\n",
    "        temperature=0\n",
    "    )\n",
    "    \n",
    "    # 从响应中提取命题\n",
    "    raw_propositions = response.choices[0].message.content.strip().split('\\n')\n",
    "    \n",
    "    # 清理命题（移除编号、项目符号等）\n",
    "    clean_propositions = []\n",
    "    for prop in raw_propositions:\n",
    "        # 移除编号（1.、2. 等）和项目符号\n",
    "        cleaned = re.sub(r'^\\s*(\\d+\\.|\\-|\\*)\\s*', '', prop).strip()\n",
    "        if cleaned and len(cleaned) > 10:  # 简单过滤空的或非常短的命题\n",
    "            clean_propositions.append(cleaned)\n",
    "    \n",
    "    return clean_propositions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 命题质量检查"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_proposition(proposition, original_text):\n",
    "    \"\"\"\n",
    "    基于准确性、清晰度、完整性和简洁性评估命题的质量。\n",
    "    \n",
    "    参数:\n",
    "        proposition (str): 要评估的命题\n",
    "        original_text (str): 用于比较的原始文本\n",
    "        \n",
    "    返回:\n",
    "        Dict: 每个评估维度的分数\n",
    "    \"\"\"\n",
    "    # 系统提示词，指导 AI 如何评估命题\n",
    "    system_prompt = \"\"\"你是评估从文本中提取的命题质量的专家。\n",
    "    请根据以下标准对给定命题进行评分（1-10 分）：\n",
    "\n",
    "    - 准确性：命题在多大程度上反映了原始文本中的信息\n",
    "    - 清晰度：在没有额外上下文的情况下理解命题的容易程度\n",
    "    - 完整性：命题是否包含必要的细节（日期、限定词等）\n",
    "    - 简洁性：命题是否简洁而不丢失重要信息\n",
    "\n",
    "    响应必须是有效的 JSON 格式，包含每个标准的数值分数：\n",
    "    {\"accuracy\": X, \"clarity\": X, \"completeness\": X, \"conciseness\": X}\n",
    "    \"\"\"\n",
    "\n",
    "    # 包含命题和原始文本的用户提示词\n",
    "    user_prompt = f\"\"\"命题：{proposition}\n",
    "\n",
    "    原始文本：{original_text}\n",
    "\n",
    "    请以 JSON 格式提供您的评估分数。\"\"\"\n",
    "\n",
    "    # 从模型生成响应\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"meta-llama/Llama-3.2-3B-Instruct\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ],\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "        temperature=0\n",
    "    )\n",
    "    \n",
    "    # 解析 JSON 响应\n",
    "    try:\n",
    "        scores = json.loads(response.choices[0].message.content.strip())\n",
    "        return scores\n",
    "    except json.JSONDecodeError:\n",
    "        # 如果 JSON 解析失败的后备方案\n",
    "        return {\n",
    "            \"accuracy\": 5,\n",
    "            \"clarity\": 5,\n",
    "            \"completeness\": 5,\n",
    "            \"conciseness\": 5\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 完整的命题处理流水线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_document_into_propositions(pdf_path, chunk_size=800, chunk_overlap=100, \n",
    "                                      quality_thresholds=None):\n",
    "    \"\"\"\n",
    "    将文档处理为经过质量检查的命题。\n",
    "    \n",
    "    参数:\n",
    "        pdf_path (str): PDF 文件的路径\n",
    "        chunk_size (int): 每个块的字符数大小\n",
    "        chunk_overlap (int): 块之间的重叠字符数\n",
    "        quality_thresholds (Dict): 命题质量的阈值分数\n",
    "        \n",
    "    返回:\n",
    "        Tuple[List[Dict], List[Dict]]: 原始块和命题块\n",
    "    \"\"\"\n",
    "    # 如果未提供，设置默认质量阈值\n",
    "    if quality_thresholds is None:\n",
    "        quality_thresholds = {\n",
    "            \"accuracy\": 7,\n",
    "            \"clarity\": 7,\n",
    "            \"completeness\": 7,\n",
    "            \"conciseness\": 7\n",
    "        }\n",
    "    \n",
    "    # 从 PDF 文件提取文本\n",
    "    text = extract_text_from_pdf(pdf_path)\n",
    "    \n",
    "    # 从提取的文本创建块\n",
    "    chunks = chunk_text(text, chunk_size, chunk_overlap)\n",
    "    \n",
    "    # 初始化列表来存储所有命题\n",
    "    all_propositions = []\n",
    "    \n",
    "    print(\"从块生成命题...\")\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        print(f\"处理块 {i+1}/{len(chunks)}...\")\n",
    "        \n",
    "        # 为当前块生成命题\n",
    "        chunk_propositions = generate_propositions(chunk)\n",
    "        print(f\"生成了 {len(chunk_propositions)} 个命题\")\n",
    "        \n",
    "        # 处理每个生成的命题\n",
    "        for prop in chunk_propositions:\n",
    "            proposition_data = {\n",
    "                \"text\": prop,\n",
    "                \"source_chunk_id\": chunk[\"chunk_id\"],\n",
    "                \"source_text\": chunk[\"text\"]\n",
    "            }\n",
    "            all_propositions.append(proposition_data)\n",
    "    \n",
    "    # 评估生成的命题的质量\n",
    "    print(\"\\n评估命题质量...\")\n",
    "    quality_propositions = []\n",
    "    \n",
    "    for i, prop in enumerate(all_propositions):\n",
    "        if i % 10 == 0:  # 每 10 个命题状态更新\n",
    "            print(f\"评估命题 {i+1}/{len(all_propositions)}...\")\n",
    "            \n",
    "        # 评估当前命题的质量\n",
    "        scores = evaluate_proposition(prop[\"text\"], prop[\"source_text\"])\n",
    "        prop[\"quality_scores\"] = scores\n",
    "        \n",
    "        # 检查命题是否通过质量阈值\n",
    "        passes_quality = True\n",
    "        for metric, threshold in quality_thresholds.items():\n",
    "            if scores.get(metric, 0) < threshold:\n",
    "                passes_quality = False\n",
    "                break\n",
    "        \n",
    "        if passes_quality:\n",
    "            quality_propositions.append(prop)\n",
    "        else:\n",
    "            print(f\"命题未通过质量检查：{prop['text'][:50]}...\")\n",
    "    \n",
    "    print(f\"\\n质量过滤后保留了 {len(quality_propositions)}/{len(all_propositions)} 个命题\")\n",
    "    \n",
    "    return chunks, quality_propositions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 为两种方法构建向量存储"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vector_stores(chunks, propositions):\n",
    "    \"\"\"\n",
    "    为基于块和基于命题的方法构建向量存储。\n",
    "    \n",
    "    参数:\n",
    "        chunks (List[Dict]): 原始文档块\n",
    "        propositions (List[Dict]): 经过质量过滤的命题\n",
    "        \n",
    "    返回:\n",
    "        Tuple[SimpleVectorStore, SimpleVectorStore]: 块和命题向量存储\n",
    "    \"\"\"\n",
    "    # 为块创建向量存储\n",
    "    chunk_store = SimpleVectorStore()\n",
    "    \n",
    "    # 提取块文本并创建嵌入向量\n",
    "    chunk_texts = [chunk[\"text\"] for chunk in chunks]\n",
    "    print(f\"为 {len(chunk_texts)} 个块创建嵌入向量...\")\n",
    "    chunk_embeddings = create_embeddings(chunk_texts)\n",
    "    \n",
    "    # 将块添加到向量存储中，包含元数据\n",
    "    chunk_metadata = [{\"chunk_id\": chunk[\"chunk_id\"], \"type\": \"chunk\"} for chunk in chunks]\n",
    "    chunk_store.add_items(chunk_texts, chunk_embeddings, chunk_metadata)\n",
    "    \n",
    "    # 为命题创建向量存储\n",
    "    prop_store = SimpleVectorStore()\n",
    "    \n",
    "    # 提取命题文本并创建嵌入向量\n",
    "    prop_texts = [prop[\"text\"] for prop in propositions]\n",
    "    print(f\"为 {len(prop_texts)} 个命题创建嵌入向量...\")\n",
    "    prop_embeddings = create_embeddings(prop_texts)\n",
    "    \n",
    "    # 将命题添加到向量存储中，包含元数据\n",
    "    prop_metadata = [\n",
    "        {\n",
    "            \"type\": \"proposition\", \n",
    "            \"source_chunk_id\": prop[\"source_chunk_id\"],\n",
    "            \"quality_scores\": prop[\"quality_scores\"]\n",
    "        } \n",
    "        for prop in propositions\n",
    "    ]\n",
    "    prop_store.add_items(prop_texts, prop_embeddings, prop_metadata)\n",
    "    \n",
    "    return chunk_store, prop_store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 查询和检索函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_from_store(query, vector_store, k=5):\n",
    "    \"\"\"\n",
    "    基于查询从向量存储中检索相关项目。\n",
    "    \n",
    "    参数:\n",
    "        query (str): 用户查询\n",
    "        vector_store (SimpleVectorStore): 要搜索的向量存储\n",
    "        k (int): 要检索的结果数量\n",
    "        \n",
    "    返回:\n",
    "        List[Dict]: 检索到的项目，包含分数和元数据\n",
    "    \"\"\"\n",
    "    # 创建查询嵌入向量\n",
    "    query_embedding = create_embeddings(query)\n",
    "    \n",
    "    # 在向量存储中搜索前 k 个最相似的项目\n",
    "    results = vector_store.similarity_search(query_embedding, k=k)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_retrieval_approaches(query, chunk_store, prop_store, k=5):\n",
    "    \"\"\"\n",
    "    比较基于块和基于命题的检索方法对查询的效果。\n",
    "    \n",
    "    参数:\n",
    "        query (str): 用户查询\n",
    "        chunk_store (SimpleVectorStore): 基于块的向量存储\n",
    "        prop_store (SimpleVectorStore): 基于命题的向量存储\n",
    "        k (int): 从每个存储中检索的结果数量\n",
    "        \n",
    "    返回:\n",
    "        Dict: 比较结果\n",
    "    \"\"\"\n",
    "    print(f\"\\n=== 查询：{query} ===\")\n",
    "    \n",
    "    # 从基于命题的向量存储中检索结果\n",
    "    print(\"\\n使用基于命题的方法检索...\")\n",
    "    prop_results = retrieve_from_store(query, prop_store, k)\n",
    "    \n",
    "    # 从基于块的向量存储中检索结果\n",
    "    print(\"使用基于块的方法检索...\")\n",
    "    chunk_results = retrieve_from_store(query, chunk_store, k)\n",
    "    \n",
    "    # 显示基于命题的结果\n",
    "    print(\"\\n=== 基于命题的结果 ===\")\n",
    "    for i, result in enumerate(prop_results):\n",
    "        print(f\"{i+1}) {result['text']} (分数：{result['similarity']:.4f})\")\n",
    "    \n",
    "    # 显示基于块的结果\n",
    "    print(\"\\n=== 基于块的结果 ===\")\n",
    "    for i, result in enumerate(chunk_results):\n",
    "        # 截断文本以保持输出可管理\n",
    "        truncated_text = result['text'][:150] + \"...\" if len(result['text']) > 150 else result['text']\n",
    "        print(f\"{i+1}) {truncated_text} (分数：{result['similarity']:.4f})\")\n",
    "    \n",
    "    # 返回比较结果\n",
    "    return {\n",
    "        \"query\": query,\n",
    "        \"proposition_results\": prop_results,\n",
    "        \"chunk_results\": chunk_results\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 响应生成和评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(query, results, result_type=\"proposition\"):\n",
    "    \"\"\"\n",
    "    基于检索结果生成响应。\n",
    "    \n",
    "    参数:\n",
    "        query (str): 用户查询\n",
    "        results (List[Dict]): 检索到的项目\n",
    "        result_type (str): 结果类型（'proposition' 或 'chunk'）\n",
    "        \n",
    "    返回:\n",
    "        str: 生成的响应\n",
    "    \"\"\"\n",
    "    # 将检索到的文本合并为单个上下文字符串\n",
    "    context = \"\\n\\n\".join([result[\"text\"] for result in results])\n",
    "    \n",
    "    # 系统提示词，指导 AI 如何生成响应\n",
    "    result_type_cn = \"命题\" if result_type == \"proposition\" else \"块\"\n",
    "    system_prompt = f\"\"\"你是一个基于检索信息回答问题的 AI 助手。\n",
    "你的答案应该基于从知识库中检索到的以下{result_type_cn}。\n",
    "如果检索到的信息无法回答问题，请承认这一限制。\"\"\"\n",
    "\n",
    "    # 包含查询和检索上下文的用户提示词\n",
    "    user_prompt = f\"\"\"查询：{query}\n",
    "\n",
    "检索到的{result_type_cn}：\n",
    "{context}\n",
    "\n",
    "请基于检索到的信息回答查询。\"\"\"\n",
    "\n",
    "    # 使用 OpenAI 客户端生成响应\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"meta-llama/Llama-3.2-3B-Instruct\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ],\n",
    "        temperature=0.2\n",
    "    )\n",
    "    \n",
    "    # 返回生成的响应文本\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_responses(query, prop_response, chunk_response, reference_answer=None):\n",
    "    \"\"\"\n",
    "    评估和比较两种方法的响应。\n",
    "    \n",
    "    参数:\n",
    "        query (str): 用户查询\n",
    "        prop_response (str): 基于命题方法的响应\n",
    "        chunk_response (str): 基于块方法的响应\n",
    "        reference_answer (str, optional): 用于比较的参考答案\n",
    "        \n",
    "    返回:\n",
    "        str: 评估分析\n",
    "    \"\"\"\n",
    "    # 系统提示词，指导 AI 如何评估响应\n",
    "    system_prompt = \"\"\"你是信息检索系统的专家评估员。\n",
    "    比较对同一查询的两个响应，一个来自基于命题的检索，\n",
    "    另一个来自基于块的检索。\n",
    "\n",
    "    基于以下标准评估它们：\n",
    "    1. 准确性：哪个响应提供了更多事实正确的信息？\n",
    "    2. 相关性：哪个响应更好地解决了具体查询？\n",
    "    3. 简洁性：哪个响应在保持完整性的同时更简洁？\n",
    "    4. 清晰度：哪个响应更容易理解？\n",
    "\n",
    "    请具体说明每种方法的优缺点。\"\"\"\n",
    "\n",
    "    # 包含查询和要比较的响应的用户提示词\n",
    "    user_prompt = f\"\"\"查询：{query}\n",
    "\n",
    "    基于命题检索的响应：\n",
    "    {prop_response}\n",
    "\n",
    "    基于块检索的响应：\n",
    "    {chunk_response}\"\"\"\n",
    "\n",
    "    # 如果提供了参考答案，将其包含在用户提示词中进行事实检查\n",
    "    if reference_answer:\n",
    "        user_prompt += f\"\"\"\n",
    "\n",
    "    参考答案（用于事实检查）：\n",
    "    {reference_answer}\"\"\"\n",
    "\n",
    "    # 向用户提示词添加最终指令\n",
    "    user_prompt += \"\"\"\n",
    "    请提供这两个响应的详细比较，突出哪种方法表现更好以及原因。\"\"\"\n",
    "\n",
    "    # 使用 OpenAI 客户端生成评估分析\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"meta-llama/Llama-3.2-3B-Instruct\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ],\n",
    "        temperature=0\n",
    "    )\n",
    "    \n",
    "    # 返回生成的评估分析\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 完整的端到端评估流水线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_proposition_chunking_evaluation(pdf_path, test_queries, reference_answers=None):\n",
    "    \"\"\"\n",
    "    运行命题分块与标准分块的完整评估。\n",
    "    \n",
    "    参数:\n",
    "        pdf_path (str): PDF 文件的路径\n",
    "        test_queries (List[str]): 测试查询列表\n",
    "        reference_answers (List[str], optional): 查询的参考答案\n",
    "        \n",
    "    返回:\n",
    "        Dict: 评估结果\n",
    "    \"\"\"\n",
    "    print(\"=== 开始命题分块评估 ===\\n\")\n",
    "    \n",
    "    # 将文档处理为命题和块\n",
    "    chunks, propositions = process_document_into_propositions(pdf_path)\n",
    "    \n",
    "    # 为块和命题构建向量存储\n",
    "    chunk_store, prop_store = build_vector_stores(chunks, propositions)\n",
    "    \n",
    "    # 初始化列表来存储每个查询的结果\n",
    "    results = []\n",
    "    \n",
    "    # 为每个查询运行测试\n",
    "    for i, query in enumerate(test_queries):\n",
    "        print(f\"\\n\\n=== 测试查询 {i+1}/{len(test_queries)} ===\")\n",
    "        print(f\"查询：{query}\")\n",
    "        \n",
    "        # 从基于块和基于命题的方法获取检索结果\n",
    "        retrieval_results = compare_retrieval_approaches(query, chunk_store, prop_store)\n",
    "        \n",
    "        # 基于检索到的基于命题的结果生成响应\n",
    "        print(\"\\n从基于命题的结果生成响应...\")\n",
    "        prop_response = generate_response(\n",
    "            query, \n",
    "            retrieval_results[\"proposition_results\"], \n",
    "            \"proposition\"\n",
    "        )\n",
    "        \n",
    "        # 基于检索到的基于块的结果生成响应\n",
    "        print(\"从基于块的结果生成响应...\")\n",
    "        chunk_response = generate_response(\n",
    "            query, \n",
    "            retrieval_results[\"chunk_results\"], \n",
    "            \"chunk\"\n",
    "        )\n",
    "        \n",
    "        # 如果可用，获取参考答案\n",
    "        reference = None\n",
    "        if reference_answers and i < len(reference_answers):\n",
    "            reference = reference_answers[i]\n",
    "        \n",
    "        # 评估生成的响应\n",
    "        print(\"\\n评估响应...\")\n",
    "        evaluation = evaluate_responses(query, prop_response, chunk_response, reference)\n",
    "        \n",
    "        # 编译当前查询的结果\n",
    "        query_result = {\n",
    "            \"query\": query,\n",
    "            \"proposition_results\": retrieval_results[\"proposition_results\"],\n",
    "            \"chunk_results\": retrieval_results[\"chunk_results\"],\n",
    "            \"proposition_response\": prop_response,\n",
    "            \"chunk_response\": chunk_response,\n",
    "            \"reference_answer\": reference,\n",
    "            \"evaluation\": evaluation\n",
    "        }\n",
    "        \n",
    "        # 将结果追加到总体结果列表中\n",
    "        results.append(query_result)\n",
    "        \n",
    "        # 打印当前查询的响应和评估\n",
    "        print(\"\\n=== 基于命题的响应 ===\")\n",
    "        print(prop_response)\n",
    "        \n",
    "        print(\"\\n=== 基于块的响应 ===\")\n",
    "        print(chunk_response)\n",
    "        \n",
    "        print(\"\\n=== 评估 ===\")\n",
    "        print(evaluation)\n",
    "    \n",
    "    # 生成评估的总体分析\n",
    "    print(\"\\n\\n=== 生成总体分析 ===\")\n",
    "    overall_analysis = generate_overall_analysis(results)\n",
    "    print(\"\\n\" + overall_analysis)\n",
    "    \n",
    "    # 返回评估结果、总体分析以及命题和块的计数\n",
    "    return {\n",
    "        \"results\": results,\n",
    "        \"overall_analysis\": overall_analysis,\n",
    "        \"proposition_count\": len(propositions),\n",
    "        \"chunk_count\": len(chunks)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_overall_analysis(results):\n",
    "    \"\"\"\n",
    "    生成命题与块方法的总体分析。\n",
    "    \n",
    "    参数:\n",
    "        results (List[Dict]): 每个测试查询的结果\n",
    "        \n",
    "    返回:\n",
    "        str: 总体分析\n",
    "    \"\"\"\n",
    "    # 系统提示词，指导 AI 如何生成总体分析\n",
    "    system_prompt = \"\"\"你是评估信息检索系统的专家。\n",
    "    基于多个测试查询，提供比较基于命题的检索与基于块的检索\n",
    "    在 RAG（检索增强生成）系统中的总体分析。\n",
    "\n",
    "    重点关注：\n",
    "    1. 基于命题的检索何时表现更好\n",
    "    2. 基于块的检索何时表现更好\n",
    "    3. 每种方法的总体优缺点\n",
    "    4. 何时使用每种方法的建议\"\"\"\n",
    "\n",
    "    # 为每个查询创建评估摘要\n",
    "    evaluations_summary = \"\"\n",
    "    for i, result in enumerate(results):\n",
    "        evaluations_summary += f\"查询 {i+1}：{result['query']}\\n\"\n",
    "        evaluations_summary += f\"评估摘要：{result['evaluation'][:200]}...\\n\\n\"\n",
    "\n",
    "    # 包含评估摘要的用户提示词\n",
    "    user_prompt = f\"\"\"基于以下对 {len(results)} 个查询的基于命题与基于块检索的评估，\n",
    "    提供比较这两种方法的总体分析：\n",
    "\n",
    "    {evaluations_summary}\n",
    "\n",
    "    请提供关于基于命题和基于块检索在 RAG 系统中相对优缺点的全面分析。\"\"\"\n",
    "\n",
    "    # 使用 OpenAI 客户端生成总体分析\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"meta-llama/Llama-3.2-3B-Instruct\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ],\n",
    "        temperature=0\n",
    "    )\n",
    "    \n",
    "    # 返回生成的分析文本\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 命题分块的评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将要处理的 AI 信息文档的路径\n",
    "pdf_path = \"data/AI_Information.pdf\"\n",
    "\n",
    "# 定义涵盖 AI 不同方面的测试查询来评估命题分块\n",
    "test_queries = [\n",
    "    \"AI 开发中的主要伦理关注点是什么？\",\n",
    "    # \"可解释的 AI 如何提高对 AI 系统的信任？\",\n",
    "    # \"开发公平 AI 系统的关键挑战是什么？\",\n",
    "    # \"人类监督在 AI 安全中起什么作用？\"\n",
    "]\n",
    "\n",
    "# 用于更彻底评估和比较结果的参考答案\n",
    "# 这些提供了衡量生成响应质量的基准真相\n",
    "reference_answers = [\n",
    "    \"AI 开发中的主要伦理关注点包括偏见和公平性、隐私、透明度、问责制、安全性，以及误用或有害应用的潜力。\",\n",
    "    # \"可解释的 AI 通过使 AI 决策过程透明且用户可理解来提高信任，帮助他们验证公平性、识别潜在偏见，并更好地理解 AI 的局限性。\",\n",
    "    # \"开发公平 AI 系统的关键挑战包括解决数据偏见、确保训练数据中的多样化代表性、创建透明算法、在不同上下文中定义公平性，以及平衡竞争的公平性标准。\",\n",
    "    # \"人类监督在 AI 安全中起关键作用，通过监控系统行为、验证输出、必要时进行干预、设定伦理边界，并确保 AI 系统在整个运行过程中与人类价值观和意图保持一致。\"\n",
    "]\n",
    "\n",
    "# 运行评估\n",
    "evaluation_results = run_proposition_chunking_evaluation(\n",
    "    pdf_path=pdf_path,\n",
    "    test_queries=test_queries,\n",
    "    reference_answers=reference_answers\n",
    ")\n",
    "\n",
    "# 打印总体分析\n",
    "print(\"\\n\\n=== 总体分析 ===\")\n",
    "print(evaluation_results[\"overall_analysis\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-new-specific-rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}