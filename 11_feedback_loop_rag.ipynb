{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG 中的反馈循环\n",
    "\n",
    "带有反馈循环机制的 RAG 系统，能够使其持续不断地自我改进。通过收集和整合用户反馈，系统在每一次交互中都能学会提供更相关、更高质量的响应。\n",
    "\n",
    "传统的 RAG 系统是静态的——它们完全基于嵌入相似度来检索信息。而通过反馈循环，可以创建了一个动态系统，它能够：\n",
    "\n",
    "-   记住哪些方法有效（哪些无效）\n",
    "-   随时间调整文档的相关性分数\n",
    "-   将成功的问答对（Q&A pairs）整合进其知识库\n",
    "-   在每次用户交互中变得更加智能"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "导入相关的库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymupdf\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import openai\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "提取pdf文本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Understanding Artificial Intelligence \n",
      "Chapter 1: Introduction to Artificial Intelligence \n",
      "Artificial intelligence (AI) refers to the ability of a digital computer or computer-controlled robot \n",
      "to perform tasks commonly associated with intelligent beings. The term is frequently applied to \n",
      "the project of developing systems endowed with the intellectual processes characteristic of \n",
      "humans, such as the ability to reason, discover meaning, generalize, or learn from past \n",
      "experience. Over the past f\n"
     ]
    }
   ],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"\n",
    "    提取PDF文件中的文本并打印前`num_chars`个字符。\n",
    "\n",
    "    参数：\n",
    "    pdf_path (str): PDF文件的路径。\n",
    "\n",
    "    返回：\n",
    "    str: 从PDF中提取的文本。\n",
    "\n",
    "    \"\"\"\n",
    "    # 打开PDF文件\n",
    "    mypdf = pymupdf.open(pdf_path)\n",
    "    all_text = \"\"  # 初始化一个空字符串来存储提取的文本\n",
    "\n",
    "    # 迭代PDF中的每个页面\n",
    "    for page_num in range(mypdf.page_count):\n",
    "        page = mypdf[page_num]  # 获取页面\n",
    "        text = page.get_text(\"text\")  # 从页面中提取文本\n",
    "        all_text += text  # 将提取的文本附加到all_text字符串\n",
    "\n",
    "    return all_text  # 返回提取的文本\n",
    "\n",
    "pdf_path = \"data/AI_Information.pdf\"\n",
    "\n",
    "\n",
    "extracted_text = extract_text_from_pdf(pdf_path)\n",
    "\n",
    "print(extracted_text[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "分块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text(text, n, overlap):\n",
    "    \"\"\"\n",
    "    将文本分割为多个块，每个块的大小为n，重叠部分为overlap。\n",
    "    参数：\n",
    "    text: 输入的文本\n",
    "    n: 每个块的大小\n",
    "    overlap: 相邻块之间的重叠部分大小\n",
    "\n",
    "    返回：\n",
    "    文本块列表\n",
    "    \"\"\"\n",
    "    chunks = []  \n",
    "    for i in range(0, len(text), n - overlap):\n",
    "        \n",
    "        chunks.append(text[i:i + n])\n",
    "    \n",
    "    return chunks  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "配置client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = openai.OpenAI(\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\"),  # 如果您没有配置环境变量，请在此处用您的API Key进行替换\n",
    "    base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\"  # 百炼服务的base_url\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "简易向量库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleVectorStore:\n",
    "    \"\"\"\n",
    "    简易的向量存储库。\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.vectors = []\n",
    "        self.texts = []\n",
    "        self.metadata = []\n",
    "    \n",
    "    def add_item(self, text, embedding, metadata=None):\n",
    "        \"\"\"\n",
    "        添加一个新的项到存储库。\n",
    "\n",
    "        参数:\n",
    "        text (str): 文本内容。\n",
    "        embedding (List[float]): 文本的嵌入向量。\n",
    "        metadata (Dict, optional): 与文本相关的元数据。\n",
    "        \"\"\"\n",
    "        self.vectors.append(np.array(embedding))\n",
    "        self.texts.append(text)\n",
    "        self.metadata.append(metadata or {})\n",
    "    \n",
    "    def similarity_search(self, query_embedding, k=5):\n",
    "        \"\"\"\n",
    "        查找与查询嵌入向量最相似的文本。\n",
    "\n",
    "        参数:\n",
    "        query_embedding (List[float]): 查询的嵌入向量。\n",
    "        k (int, optional): 返回最相似的k个结果。\n",
    "\n",
    "        返回:\n",
    "        List[Dict]: 最相似的文本及其相关信息。\n",
    "        \"\"\"\n",
    "        if not self.vectors:\n",
    "            return []\n",
    "        \n",
    "\n",
    "        query_vector = np.array(query_embedding)\n",
    "        \n",
    "\n",
    "        similarities = []\n",
    "        for i, vector in enumerate(self.vectors):\n",
    "            similarity = np.dot(query_vector, vector) / (np.linalg.norm(query_vector) * np.linalg.norm(vector))\n",
    "            similarities.append((i, similarity))\n",
    "        \n",
    "\n",
    "        similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "\n",
    "        results = []\n",
    "        for i in range(min(k, len(similarities))):\n",
    "            idx, score = similarities[i]\n",
    "            results.append({\n",
    "                \"text\": self.texts[idx],\n",
    "                \"metadata\": self.metadata[idx],\n",
    "                \"similarity\": score\n",
    "            })\n",
    "        \n",
    "        return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "生成向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embeddings_in_batches(text_chunks, model=\"text-embedding-v3\", batch_size_limit=10): # 我改成了官方模型名，你可以换回 \"text-embedding-v3\"\n",
    "    \"\"\"\n",
    "    调用 OpenAI 的 Embedding API 来创建文本列表的嵌入向量，处理批处理大小限制。\n",
    "\n",
    "    参数:\n",
    "    text_chunks (List[str]): 需要创建嵌入的文本字符串列表。\n",
    "    model (str): 使用的嵌入模型。\n",
    "    batch_size_limit (int): API 允许的最大批处理大小。根据错误信息，这里是10。\n",
    "\n",
    "    返回:\n",
    "    List[List[float]]: 所有文本的嵌入向量列表。\n",
    "    \"\"\"\n",
    "    all_embeddings = []\n",
    "    if not text_chunks:\n",
    "        return []\n",
    "\n",
    "    if not isinstance(text_chunks, list): # 确保输入是列表\n",
    "        text_chunks = [text_chunks]\n",
    "\n",
    "    for i in range(0, len(text_chunks), batch_size_limit):\n",
    "        batch = text_chunks[i:i + batch_size_limit]\n",
    "        try:\n",
    "            #print(f\"Processing batch {i//batch_size_limit + 1}, size: {len(batch)}\")\n",
    "            response = client.embeddings.create(\n",
    "                input=batch,\n",
    "                model=model,\n",
    "                encoding_format=\"float\"\n",
    "            )\n",
    "            # 从响应中提取该批次的嵌入向量\n",
    "            batch_embeddings = [item.embedding for item in response.data]\n",
    "            all_embeddings.extend(batch_embeddings)\n",
    "\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing batch starting with chunk: '{batch[0][:50]}...'\")\n",
    "            print(f\"API Error: {e}\")\n",
    "\n",
    "            raise e \n",
    "\n",
    "    return all_embeddings\n",
    "\n",
    "def create_embeddings(text, model=\"text-embedding-v3\"):\n",
    "    \"\"\"\n",
    "    字符串向量化\n",
    "    参数:\n",
    "    text (str): 需要创建嵌入的文本字符串。\n",
    "    model (str): 使用的嵌入模型。\n",
    "\n",
    "    返回:\n",
    "    List[float]: 文本的嵌入向量。\n",
    "    \"\"\"\n",
    "    response = client.embeddings.create(\n",
    "        model=model,\n",
    "        input=text\n",
    "    )\n",
    "\n",
    "    return response.data[0].embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "反馈系统"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_feedback(query, response, relevance, quality, comments=\"\"):\n",
    "    \"\"\"\n",
    "    格式化用户反馈。\n",
    "\n",
    "    Args:\n",
    "        query (str): 用户查询\n",
    "        response (str): 模型响应\n",
    "        relevance (bool): 响应是否与查询相关\n",
    "        quality (bool): 响应质量是否良好\n",
    "        comments (str): 可选的反馈评论\n",
    "\n",
    "    Returns:\n",
    "        dict: 格式化的反馈\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"query\": query,\n",
    "        \"response\": response,\n",
    "        \"relevance\": int(relevance),\n",
    "        \"quality\": int(quality),\n",
    "        \"comments\": comments,\n",
    "        \"timestamp\": datetime.now().isoformat()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_feedback(feedback, feedback_file=\"feedback_data.json\"):\n",
    "    \"\"\"\n",
    "    存储反馈到文件。\n",
    "\n",
    "    Args:\n",
    "        feedback (Dict): 用户反馈\n",
    "        feedback_file (str): 存储反馈的文件名\n",
    "    \"\"\"\n",
    "    with open(feedback_file, \"a\") as f:\n",
    "        json.dump(feedback, f)\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_feedback_data(feedback_file=\"feedback_data.json\"):\n",
    "    \"\"\"\n",
    "    加载反馈数据\n",
    "    \"\"\"\n",
    "    feedback_data = []\n",
    "    try:\n",
    "        with open(feedback_file, \"r\") as f:\n",
    "            for line in f:\n",
    "                if line.strip():\n",
    "                    feedback_data.append(json.loads(line.strip()))\n",
    "    except FileNotFoundError:\n",
    "        print(\"No feedback data file found. Starting with empty feedback.\")\n",
    "    \n",
    "    return feedback_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "文本处理和反馈流程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_document(pdf_path, chunk_size=1000, chunk_overlap=200):\n",
    "    \"\"\"\n",
    "    处理带有反馈循环的RAG（检索增强生成）文档。\n",
    "    此函数处理完整的文档处理管道：\n",
    "    1、从PDF中提取文本\n",
    "    2、重叠文本分块\n",
    "    3、嵌入区块创建\n",
    "    4、矢量数据库元数据存储\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Extracting text from PDF...\")\n",
    "    extracted_text = extract_text_from_pdf(pdf_path)\n",
    "    \n",
    "    print(\"Chunking text...\")\n",
    "    chunks = chunk_text(extracted_text, chunk_size, chunk_overlap)\n",
    "    print(f\"Created {len(chunks)} text chunks\")\n",
    "    \n",
    "\n",
    "    print(\"Creating embeddings for chunks...\")\n",
    "    chunk_embeddings = create_embeddings_in_batches(chunks)\n",
    "    \n",
    "    store = SimpleVectorStore()\n",
    "\n",
    "    for i, (chunk, embedding) in enumerate(zip(chunks, chunk_embeddings)):\n",
    "        store.add_item(\n",
    "            text=chunk,\n",
    "            embedding=embedding,\n",
    "            metadata={\n",
    "                \"index\": i,                \n",
    "                \"source\": pdf_path,     \n",
    "                \"relevance_score\": 1.0,   \n",
    "                \"feedback_count\": 0        \n",
    "            }\n",
    "        )\n",
    "    \n",
    "    print(f\"Added {len(chunks)} chunks to the vector store\")\n",
    "    return chunks, store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "基于反馈的相关性调整"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assess_feedback_relevance(query, doc_text, feedback):\n",
    "    \"\"\"\n",
    "    使用llm来评估反馈的相关性\n",
    "    Args:\n",
    "        query (str): 当前的查询\n",
    "        doc_text (str): 文档的文本内容\n",
    "        feedback (dict): 包含查询、响应、评论和评分的反馈字典\n",
    "    Returns:\n",
    "        bool: 如果反馈与查询相关，则返回True；否则返回False\n",
    "    \"\"\"\n",
    "    system_prompt = \"\"\"You are an AI system that determines if a past feedback is relevant to a current query and document.\n",
    "    Answer with ONLY 'yes' or 'no'. Your job is strictly to determine relevance, not to provide explanations.\"\"\"\n",
    "\n",
    "    user_prompt = f\"\"\"\n",
    "    Current query: {query}\n",
    "    Past query that received feedback: {feedback['query']}\n",
    "    Document content: {doc_text[:500]}... [truncated]\n",
    "    Past response that received feedback: {feedback['response'][:500]}... [truncated]\n",
    "\n",
    "    Is this past feedback relevant to the current query and document? (yes/no)\n",
    "    \"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"qwen-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ],\n",
    "        extra_body={\n",
    "            \"enable_thinking\": False,\n",
    "            \"temperature\": 0\n",
    "            }\n",
    "    )\n",
    "    \n",
    "    answer = response.choices[0].message.content.strip().lower()\n",
    "    return 'yes' in answer  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_relevance_scores(query, results, feedback_data):\n",
    "    \"\"\"\n",
    "    根据历史反馈调整文档相关性得分以提高检索质量。\n",
    "    \n",
    "    此功能分析过去的用户反馈，动态调整\n",
    "    检索到的文档。它标识与当前查询上下文相关的反馈，\n",
    "    根据相关性评级计算分数修饰符，并相应地对结果重新排序。\n",
    "    \n",
    "    Args:\n",
    "        query (str): 用户的查询文本\n",
    "        results (List[Dict]): 包含文档文本和相似度得分的检索结果\n",
    "        feedback_data (List[Dict]): 包含用户反馈的历史记录\n",
    "        \n",
    "    Returns:\n",
    "        List[Dict]: 调整后的检索结果\n",
    "    \"\"\"\n",
    "    \n",
    "    if not feedback_data:\n",
    "        return results\n",
    "    \n",
    "    print(\"Adjusting relevance scores based on feedback history...\")\n",
    "    \n",
    "    for i, result in enumerate(results):\n",
    "        document_text = result[\"text\"]\n",
    "        relevant_feedback = []\n",
    "        \n",
    "        for feedback in feedback_data:\n",
    "            is_relevant = assess_feedback_relevance(query, document_text, feedback)\n",
    "            if is_relevant:\n",
    "                relevant_feedback.append(feedback)\n",
    "       \n",
    "        if relevant_feedback:\n",
    "            \n",
    "            avg_relevance = sum(f['relevance'] for f in relevant_feedback) / len(relevant_feedback)\n",
    "            \n",
    "            modifier = 0.5 + (avg_relevance / 5.0)\n",
    "\n",
    "            original_score = result[\"similarity\"]\n",
    "            adjusted_score = original_score * modifier\n",
    "            \n",
    "            result[\"original_similarity\"] = original_score  \n",
    "            result[\"similarity\"] = adjusted_score           \n",
    "            result[\"relevance_score\"] = adjusted_score      \n",
    "            result[\"feedback_applied\"] = True               \n",
    "            result[\"feedback_count\"] = len(relevant_feedback)  \n",
    "            \n",
    "            print(f\"  Document {i+1}: Adjusted score from {original_score:.4f} to {adjusted_score:.4f} based on {len(relevant_feedback)} feedback(s)\")\n",
    "    \n",
    "    results.sort(key=lambda x: x[\"similarity\"], reverse=True)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用反馈来微调RAG模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fine_tune_index(current_store, chunks, feedback_data):\n",
    "    \"\"\"\n",
    "    使用高质量反馈增强向量存储，以随时间提高检索质量。\n",
    "    \n",
    "    此功能通过以下方式实现连续学习过程：\n",
    "    1、识别高质量反馈（高评分问答对）\n",
    "    2、从成功交互中新建检索项\n",
    "    3、使用增强的相关权重将其添加到向量存储中\n",
    "\n",
    "    参数:\n",
    "    current_store (SimpleVectorStore): 当前的向量存储，包含原始文档块\n",
    "    chunks (List[str]): 原始文档文本块\n",
    "    feedback_data (List[Dict]): 历史用户反馈，包括相关性和质量评分\n",
    "\n",
    "    返回:\n",
    "    SimpleVectorStore: 增强的向量存储，包含原始块和从成功交互中派生的内容\n",
    "    \n",
    "    \"\"\"\n",
    "    print(\"Fine-tuning index with high-quality feedback...\")\n",
    "    \n",
    "\n",
    "    good_feedback = [f for f in feedback_data if f['relevance'] >= 4 and f['quality'] >= 4]\n",
    "    \n",
    "    if not good_feedback:\n",
    "        print(\"No high-quality feedback found for fine-tuning.\")\n",
    "        return current_store  \n",
    "    \n",
    "    new_store = SimpleVectorStore()\n",
    "\n",
    "    for i in range(len(current_store.texts)):\n",
    "        new_store.add_item(\n",
    "            text=current_store.texts[i],\n",
    "            embedding=current_store.vectors[i],\n",
    "            metadata=current_store.metadata[i].copy()  \n",
    "        )\n",
    "\n",
    "    for feedback in good_feedback:\n",
    "\n",
    "        enhanced_text = f\"Question: {feedback['query']}\\nAnswer: {feedback['response']}\"\n",
    "        \n",
    "        embedding = create_embeddings(enhanced_text)\n",
    "\n",
    "        new_store.add_item(\n",
    "            text=enhanced_text,\n",
    "            embedding=embedding,\n",
    "            metadata={\n",
    "                \"type\": \"feedback_enhanced\",  \n",
    "                \"query\": feedback[\"query\"],   \n",
    "                \"relevance_score\": 1.2,       \n",
    "                \"feedback_count\": 1,          \n",
    "                \"original_feedback\": feedback \n",
    "            }\n",
    "        )\n",
    "        \n",
    "        print(f\"Added enhanced content from feedback: {feedback['query'][:50]}...\")\n",
    "    print(f\"Fine-tuned index now has {len(new_store.texts)} items (original: {len(chunks)})\")\n",
    "    return new_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(query, context, model=\"qwen3-4b\"):\n",
    "\n",
    "    system_prompt = \"\"\"You are a helpful AI assistant. Answer the user's question based only on the provided context. If you cannot find the answer in the context, state that you don't have enough information.\"\"\"\n",
    "\n",
    "    user_prompt = f\"\"\"\n",
    "        Context:\n",
    "        {context}\n",
    "\n",
    "        Question: {query}\n",
    "\n",
    "        Please provide a comprehensive answer based only on the context above.\n",
    "    \"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ],\n",
    "        extra_body={\n",
    "            \"enable_thinking\": False,\n",
    "            \"temperature\": 0\n",
    "            }\n",
    "\n",
    "    )\n",
    "    \n",
    "    # Return the generated response content\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_with_feedback_loop(query, vector_store, feedback_data, k=5, model=\"qwen3-4b\"):\n",
    "    \"\"\"\n",
    "    完整的RAG流程，包括反馈循环。\n",
    "    \n",
    "    Args:\n",
    "        query (str): 用户的查询\n",
    "        vector_store (SimpleVectorStore): 包含文档片段的向量存储\n",
    "        feedback_data (List[Dict]): 历史用户反馈，包含查询、响应、相关性和质量评分\n",
    "        k (int): 初始检索时考虑的文档片段数量\n",
    "        model (str): 用于生成响应的LLM模型\n",
    "\n",
    "    Returns:    \n",
    "        Dict: 包含查询、检索到的文档片段和生成的响应的结果\n",
    "    \"\"\"\n",
    "    print(f\"\\n=== Processing query with feedback-enhanced RAG ===\")\n",
    "    print(f\"Query: {query}\")\n",
    "    \n",
    "    query_embedding = create_embeddings(query)\n",
    "    \n",
    "    results = vector_store.similarity_search(query_embedding, k=k)\n",
    "    \n",
    "    adjusted_results = adjust_relevance_scores(query, results, feedback_data)\n",
    "    \n",
    "\n",
    "    retrieved_texts = [result[\"text\"] for result in adjusted_results]\n",
    "    \n",
    "    context = \"\\n\\n---\\n\\n\".join(retrieved_texts)\n",
    "\n",
    "    print(\"Generating response...\")\n",
    "    response = generate_response(query, context, model)\n",
    "\n",
    "    result = {\n",
    "        \"query\": query,\n",
    "        \"retrieved_documents\": adjusted_results,\n",
    "        \"response\": response\n",
    "    }\n",
    "    \n",
    "    print(\"\\n=== Response ===\")\n",
    "    print(response)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "完整工作流：从初始化到反馈收集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_rag_workflow(pdf_path, query, feedback_data=None, feedback_file=\"feedback_data.json\", fine_tune=False):\n",
    "    \"\"\"\n",
    "    执行完整的RAG工作流程，并进行反馈集成，以持续改进。\n",
    "    \n",
    "    此函数协调整个检索增强生成过程：\n",
    "    1、加载历史反馈数据\n",
    "    2、文件处理分块\n",
    "    3、可选择使用事先反馈微调向量索引\n",
    "    4、利用反馈调整的相关性得分进行检索和生成\n",
    "    5、收集新用户反馈，以便今后改进\n",
    "    6、存储反馈，以便随时间进行系统学习\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    if feedback_data is None:\n",
    "        feedback_data = load_feedback_data(feedback_file)\n",
    "        print(f\"Loaded {len(feedback_data)} feedback entries from {feedback_file}\")\n",
    "    \n",
    "    chunks, vector_store = process_document(pdf_path)\n",
    "    \n",
    "    if fine_tune and feedback_data:\n",
    "        vector_store = fine_tune_index(vector_store, chunks, feedback_data)\n",
    "\n",
    "    result = rag_with_feedback_loop(query, vector_store, feedback_data)\n",
    "    \n",
    "    print(\"\\n=== Would you like to provide feedback on this response? ===\")\n",
    "    print(\"Rate relevance (1-5, with 5 being most relevant):\")\n",
    "    relevance = input()\n",
    "    \n",
    "    print(\"Rate quality (1-5, with 5 being highest quality):\")\n",
    "    quality = input()\n",
    "    \n",
    "    print(\"Any comments? (optional, press Enter to skip)\")\n",
    "    comments = input()\n",
    "\n",
    "    feedback = get_user_feedback(\n",
    "        query=query,\n",
    "        response=result[\"response\"],\n",
    "        relevance=int(relevance),\n",
    "        quality=int(quality),\n",
    "        comments=comments\n",
    "    )\n",
    "    \n",
    "    store_feedback(feedback, feedback_file)\n",
    "    print(\"Feedback recorded. Thank you!\")\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_feedback_loop(pdf_path, test_queries, reference_answers=None):\n",
    "    \"\"\"\n",
    "    通过比较反馈集成前后的性能，评估反馈回路对抹布质量的影响。\n",
    "    \n",
    "    此函数运行受控实验，以测量合并反馈如何影响检索和生成：\n",
    "    1、第一轮：运行所有测试查询，无反馈\n",
    "    2、根据参考答案生成综合反馈（如果提供）\n",
    "    3、第二轮：使用反馈增强检索运行相同的查询\n",
    "    4、比较轮间结果，量化反馈影响\n",
    "\n",
    "    \"\"\"\n",
    "    print(\"=== Evaluating Feedback Loop Impact ===\")\n",
    "    \n",
    "    temp_feedback_file = \"temp_evaluation_feedback.json\"\n",
    "    \n",
    "    feedback_data = []\n",
    "    \n",
    "    print(\"\\n=== ROUND 1: NO FEEDBACK ===\")\n",
    "    round1_results = []\n",
    "    \n",
    "    for i, query in enumerate(test_queries):\n",
    "        print(f\"\\nQuery {i+1}: {query}\")\n",
    "        chunks, vector_store = process_document(pdf_path)\n",
    "\n",
    "        result = rag_with_feedback_loop(query, vector_store, [])\n",
    "        round1_results.append(result)\n",
    "        \n",
    "        if reference_answers and i < len(reference_answers):\n",
    "\n",
    "            similarity_to_ref = calculate_similarity(result[\"response\"], reference_answers[i])\n",
    "\n",
    "            relevance = max(1, min(5, int(similarity_to_ref * 5)))\n",
    "            quality = max(1, min(5, int(similarity_to_ref * 5)))\n",
    "\n",
    "            feedback = get_user_feedback(\n",
    "                query=query,\n",
    "                response=result[\"response\"],\n",
    "                relevance=relevance,\n",
    "                quality=quality,\n",
    "                comments=f\"Synthetic feedback based on reference similarity: {similarity_to_ref:.2f}\"\n",
    "            )\n",
    "\n",
    "            feedback_data.append(feedback)\n",
    "            store_feedback(feedback, temp_feedback_file)\n",
    "    \n",
    "    print(\"\\n=== ROUND 2: WITH FEEDBACK ===\")\n",
    "    round2_results = []\n",
    "    \n",
    "    chunks, vector_store = process_document(pdf_path)\n",
    "    vector_store = fine_tune_index(vector_store, chunks, feedback_data)\n",
    "    \n",
    "    for i, query in enumerate(test_queries):\n",
    "        print(f\"\\nQuery {i+1}: {query}\")\n",
    "\n",
    "        result = rag_with_feedback_loop(query, vector_store, feedback_data)\n",
    "        round2_results.append(result)\n",
    "\n",
    "    comparison = compare_results(test_queries, round1_results, round2_results, reference_answers)\n",
    "\n",
    "    if os.path.exists(temp_feedback_file):\n",
    "        os.remove(temp_feedback_file)\n",
    "    \n",
    "    return {\n",
    "        \"round1_results\": round1_results,\n",
    "        \"round2_results\": round2_results,\n",
    "        \"comparison\": comparison\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_similarity(text1, text2):\n",
    "    \"\"\"\n",
    "    计算两个文本的相似度。\n",
    "    \"\"\"\n",
    "\n",
    "    embedding1 = create_embeddings(text1)\n",
    "    embedding2 = create_embeddings(text2)\n",
    "\n",
    "    vec1 = np.array(embedding1)\n",
    "    vec2 = np.array(embedding2)\n",
    "\n",
    "    similarity = np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
    "    \n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_results(queries, round1_results, round2_results, reference_answers=None):\n",
    "    \"\"\"\n",
    "    比较两个RAG系统的结果。\n",
    "\n",
    "    \"\"\"\n",
    "    print(\"\\n=== COMPARING RESULTS ===\")\n",
    "    \n",
    "    system_prompt = \"\"\"You are an expert evaluator of RAG systems. Compare responses from two versions:\n",
    "        1. Standard RAG: No feedback used\n",
    "        2. Feedback-enhanced RAG: Uses a feedback loop to improve retrieval\n",
    "\n",
    "        Analyze which version provides better responses in terms of:\n",
    "        - Relevance to the query\n",
    "        - Accuracy of information\n",
    "        - Completeness\n",
    "        - Clarity and conciseness\n",
    "    \"\"\"\n",
    "\n",
    "    comparisons = []\n",
    "\n",
    "    for i, (query, r1, r2) in enumerate(zip(queries, round1_results, round2_results)):\n",
    "\n",
    "        comparison_prompt = f\"\"\"\n",
    "        Query: {query}\n",
    "\n",
    "        Standard RAG Response:\n",
    "        {r1[\"response\"]}\n",
    "\n",
    "        Feedback-enhanced RAG Response:\n",
    "        {r2[\"response\"]}\n",
    "        \"\"\"\n",
    "\n",
    "        if reference_answers and i < len(reference_answers):\n",
    "            comparison_prompt += f\"\"\"\n",
    "            Reference Answer:\n",
    "            {reference_answers[i]}\n",
    "            \"\"\"\n",
    "\n",
    "        comparison_prompt += \"\"\"\n",
    "        Compare these responses and explain which one is better and why.\n",
    "        Focus specifically on how the feedback loop has (or hasn't) improved the response quality.\n",
    "        \"\"\"\n",
    "\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"qwen-plus\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": comparison_prompt}\n",
    "            ],\n",
    "\n",
    "        )\n",
    "        \n",
    "        comparisons.append({\n",
    "            \"query\": query,\n",
    "            \"analysis\": response.choices[0].message.content\n",
    "        })\n",
    "\n",
    "        print(f\"\\nQuery {i+1}: {query}\")\n",
    "        print(f\"Analysis: {response.choices[0].message.content}...\")\n",
    "    \n",
    "    return comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Evaluating Feedback Loop Impact ===\n",
      "\n",
      "=== ROUND 1: NO FEEDBACK ===\n",
      "\n",
      "Query 1: What is a neural network and how does it function?\n",
      "Extracting text from PDF...\n",
      "Chunking text...\n",
      "Created 42 text chunks\n",
      "Creating embeddings for chunks...\n",
      "Added 42 chunks to the vector store\n",
      "\n",
      "=== Processing query with feedback-enhanced RAG ===\n",
      "Query: What is a neural network and how does it function?\n",
      "Generating response...\n",
      "\n",
      "=== Response ===\n",
      "The context provided does not explicitly define what a neural network is or explain how it functions. However, it does mention deep learning as a subfield of machine learning that uses artificial neural networks with multiple layers (deep neural networks) to analyze data, inspired by the structure and function of the human brain. It also refers to Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs), which are types of neural networks. \n",
      "\n",
      "From the context, we can infer that a neural network is a computational model inspired by the human brain, consisting of layers of interconnected nodes (neurons) that process data. These networks are used for tasks such as image recognition, natural language processing, and speech recognition. However, the specific mechanics of how a neural network functions, such as the role of activation functions, weights, and backpropagation, are not detailed in the provided text. Therefore, based on the given context, a comprehensive answer about neural networks cannot be fully provided.\n",
      "\n",
      "=== ROUND 2: WITH FEEDBACK ===\n",
      "Extracting text from PDF...\n",
      "Chunking text...\n",
      "Created 42 text chunks\n",
      "Creating embeddings for chunks...\n",
      "Added 42 chunks to the vector store\n",
      "Fine-tuning index with high-quality feedback...\n",
      "No high-quality feedback found for fine-tuning.\n",
      "\n",
      "Query 1: What is a neural network and how does it function?\n",
      "\n",
      "=== Processing query with feedback-enhanced RAG ===\n",
      "Query: What is a neural network and how does it function?\n",
      "Adjusting relevance scores based on feedback history...\n",
      "  Document 1: Adjusted score from 0.7084 to 0.7792 based on 1 feedback(s)\n",
      "  Document 2: Adjusted score from 0.6222 to 0.6844 based on 1 feedback(s)\n",
      "  Document 3: Adjusted score from 0.6093 to 0.6703 based on 1 feedback(s)\n",
      "  Document 4: Adjusted score from 0.5879 to 0.6467 based on 1 feedback(s)\n",
      "  Document 5: Adjusted score from 0.5594 to 0.6154 based on 1 feedback(s)\n",
      "Generating response...\n",
      "\n",
      "=== Response ===\n",
      "The context provided does not explicitly define what a neural network is or explain how it functions. However, it does mention deep learning as a subfield of machine learning that uses artificial neural networks with multiple layers (deep neural networks) to analyze data, inspired by the structure and function of the human brain. It also refers to Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs), which are types of neural networks. \n",
      "\n",
      "Based on the information given, a neural network is a computational model inspired by the human brain, consisting of layers of interconnected nodes (neurons) that process data. These networks are used in deep learning for tasks such as image recognition, natural language processing, and speech recognition. CNNs are particularly effective for processing images and videos, while RNNs are designed for sequential data like text and time series. However, the context does not provide a detailed explanation of how neural networks function at a fundamental level.\n",
      "\n",
      "=== COMPARING RESULTS ===\n",
      "\n",
      "Query 1: What is a neural network and how does it function?\n",
      "Analysis: ### Evaluation of Responses\n",
      "\n",
      "#### **1. Relevance to the Query**\n",
      "- **Standard RAG Response**: The response is somewhat relevant but acknowledges that the provided context lacks sufficient detail to fully define a neural network or explain its functioning. It mentions deep learning, CNNs, and RNNs but does not delve into the core mechanics of neural networks (e.g., weights, activation functions, backpropagation). This makes it less relevant for someone seeking a detailed explanation.\n",
      "  \n",
      "- **Feedback-enhanced RAG Response**: Similar to the Standard RAG response, this version also recognizes the lack of detail in the context. However, it provides slightly more structure by briefly mentioning specific use cases for CNNs and RNNs. While still not fully answering the query, it adds a bit more value compared to the Standard RAG response.\n",
      "\n",
      "**Conclusion**: Both responses are partially relevant, but the Feedback-enhanced RAG offers marginally better relevance due to additional information about CNNs and RNNs.\n",
      "\n",
      "---\n",
      "\n",
      "#### **2. Accuracy of Information**\n",
      "- **Standard RAG Response**: The information provided is accurate within the limits of the context. It correctly identifies neural networks as computational models inspired by the human brain and notes their application in tasks like image recognition and natural language processing. However, it stops short of explaining how they function, which limits its completeness.\n",
      "\n",
      "- **Feedback-enhanced RAG Response**: Like the Standard RAG response, this version accurately describes neural networks as computational models inspired by the brain. Additionally, it accurately categorizes CNNs and RNNs based on their typical applications. There are no inaccuracies in either response.\n",
      "\n",
      "**Conclusion**: Both versions maintain high accuracy, with no significant differences between them.\n",
      "\n",
      "---\n",
      "\n",
      "#### **3. Completeness**\n",
      "- **Standard RAG Response**: The response explicitly states that it cannot provide a comprehensive answer due to insufficient context. It touches on what neural networks are used for but fails to address their internal workings, leaving the user without a full understanding of how they function.\n",
      "\n",
      "- **Feedback-enhanced RAG Response**: While this version also falls short of providing a complete explanation, it supplements the basic definition with specific examples of CNNs and RNNs and their respective strengths. This slight expansion improves the overall completeness of the response.\n",
      "\n",
      "**Conclusion**: The Feedback-enhanced RAG response is more complete because it includes practical examples of different types of neural networks and their applications, even though neither response fully addresses the query.\n",
      "\n",
      "---\n",
      "\n",
      "#### **4. Clarity and Conciseness**\n",
      "- **Standard RAG Response**: The language is clear and concise, focusing on acknowledging the limitations of the context while summarizing the available information. However, the lack of depth may leave some users unsatisfied.\n",
      "\n",
      "- **Feedback-enhanced RAG Response**: This version maintains clarity and conciseness while adding useful details about CNNs and RNNs. The added content enhances the response without becoming overly verbose.\n",
      "\n",
      "**Conclusion**: Both responses are clear and concise, but the Feedback-enhanced RAG strikes a better balance between brevity and informativeness.\n",
      "\n",
      "---\n",
      "\n",
      "### **Impact of Feedback Loop**\n",
      "The feedback loop appears to have enhanced the quality of the response by:\n",
      "1. Providing additional context-specific details (e.g., CNNs for images, RNNs for sequences).\n",
      "2. Offering a more structured breakdown of neural network types and their applications.\n",
      "3. Improving the overall completeness without sacrificing clarity or conciseness.\n",
      "\n",
      "However, the fundamental limitation—lack of detailed explanation about how neural networks function—persists in both versions. The feedback loop did not compensate for missing foundational knowledge about weights, activation functions, or backpropagation.\n",
      "\n",
      "---\n",
      "\n",
      "### **Final Verdict**\n",
      "The **Feedback-enhanced RAG Response** is better than the Standard RAG Response in terms of relevance, completeness, and usefulness to the user. While both responses acknowledge the insufficiency of the context, the Feedback-enhanced version goes further by including practical examples of neural network types and their applications. \n",
      "\n",
      "If the goal is to maximize user satisfaction despite contextual limitations, the Feedback-enhanced RAG achieves this more effectively. However, if the system could incorporate richer foundational knowledge (e.g., through broader training data or external sources), both versions would benefit significantly....\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pdf_path = \"data/AI_Information.pdf\"\n",
    "\n",
    "\n",
    "test_queries = [\n",
    "    \"What is a neural network and how does it function?\",\n",
    "\n",
    "    #################################################################################\n",
    "    ### Commented out queries to reduce the number of queries for testing purposes ###\n",
    "    \n",
    "    # \"Describe the process and applications of reinforcement learning.\",\n",
    "    # \"What are the main applications of natural language processing in today's technology?\",\n",
    "    # \"Explain the impact of overfitting in machine learning models and how it can be mitigated.\"\n",
    "]\n",
    "\n",
    "\n",
    "reference_answers = [\n",
    "    \"A neural network is a series of algorithms that attempt to recognize underlying relationships in a set of data through a process that mimics the way the human brain operates. It consists of layers of nodes, with each node representing a neuron. Neural networks function by adjusting the weights of connections between nodes based on the error of the output compared to the expected result.\",\n",
    "\n",
    "    ############################################################################################\n",
    "    #### Commented out reference answers to reduce the number of queries for testing purposes ###\n",
    "\n",
    "#     \"Reinforcement learning is a type of machine learning where an agent learns to make decisions by performing actions in an environment to maximize cumulative reward. It involves exploration, exploitation, and learning from the consequences of actions. Applications include robotics, game playing, and autonomous vehicles.\",\n",
    "#     \"The main applications of natural language processing in today's technology include machine translation, sentiment analysis, chatbots, information retrieval, text summarization, and speech recognition. NLP enables machines to understand and generate human language, facilitating human-computer interaction.\",\n",
    "#     \"Overfitting in machine learning models occurs when a model learns the training data too well, capturing noise and outliers. This results in poor generalization to new data, as the model performs well on training data but poorly on unseen data. Mitigation techniques include cross-validation, regularization, pruning, and using more training data.\"\n",
    "]\n",
    "\n",
    "evaluation_results = evaluate_feedback_loop(\n",
    "    pdf_path=pdf_path,\n",
    "    test_queries=test_queries,\n",
    "    reference_answers=reference_answers\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qwen_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
