{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "source": [
    "# RAG 的分层索引\n",
    "\n",
    "在这个笔记本中，我实现了一种用于 RAG 系统的分层索引方法。这种技术通过使用两层搜索方法来改进检索：首先通过摘要识别相关的文档部分，然后从这些部分检索具体细节。\n",
    "\n",
    "传统的 RAG 方法平等对待所有文本块，这可能导致：\n",
    "\n",
    "- 当块太小时丢失上下文\n",
    "- 当文档集合很大时产生不相关的结果\n",
    "- 在整个语料库中进行低效搜索\n",
    "\n",
    "分层检索通过以下方式解决这些问题：\n",
    "\n",
    "- 为较大的文档部分创建简洁的摘要\n",
    "- 首先搜索这些摘要以识别相关部分\n",
    "- 然后仅从这些部分检索详细信息\n",
    "- 在保持具体细节的同时维护上下文"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 设置环境\n",
    "我们首先导入必要的库。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import fitz\n",
    "from openai import OpenAI\n",
    "import re\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 设置 OpenAI API 客户端\n",
    "我们初始化 OpenAI 客户端来生成嵌入向量和响应。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用基础 URL 和 API 密钥初始化 OpenAI 客户端\n",
    "client = OpenAI(\n",
    "    base_url=\"https://api.studio.nebius.com/v1/\",\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\")  # 从环境变量中获取 API 密钥\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 文档处理函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"\n",
    "    从 PDF 文件中提取文本内容，并按页面分离。\n",
    "    \n",
    "    Args:\n",
    "        pdf_path (str): PDF 文件路径\n",
    "        \n",
    "    Returns:\n",
    "        List[Dict]: 包含文本内容和元数据的页面列表\n",
    "    \"\"\"\n",
    "    print(f\"正在从 {pdf_path} 提取文本...\")  # 打印正在处理的 PDF 路径\n",
    "    pdf = fitz.open(pdf_path)  # 使用 PyMuPDF 打开 PDF 文件\n",
    "    pages = []  # 初始化空列表来存储包含文本内容的页面\n",
    "    \n",
    "    # 遍历 PDF 中的每一页\n",
    "    for page_num in range(len(pdf)):\n",
    "        page = pdf[page_num]  # 获取当前页面\n",
    "        text = page.get_text()  # 从当前页面提取文本\n",
    "        \n",
    "        # 跳过文本很少的页面（少于 50 个字符）\n",
    "        if len(text.strip()) > 50:\n",
    "            # 将页面文本和元数据追加到列表中\n",
    "            pages.append({\n",
    "                \"text\": text,\n",
    "                \"metadata\": {\n",
    "                    \"source\": pdf_path,  # 源文件路径\n",
    "                    \"page\": page_num + 1  # 页码（从 1 开始的索引）\n",
    "                }\n",
    "            })\n",
    "    \n",
    "    print(f\"提取了 {len(pages)} 页内容\")  # 打印提取的页面数量\n",
    "    return pages  # 返回包含文本内容和元数据的页面列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text(text, metadata, chunk_size=1000, overlap=200):\n",
    "    \"\"\"\n",
    "    将文本分割为重叠的块，同时保留元数据。\n",
    "    \n",
    "    Args:\n",
    "        text (str): 要分块的输入文本\n",
    "        metadata (Dict): 要保留的元数据\n",
    "        chunk_size (int): 每个块的字符大小\n",
    "        overlap (int): 块之间的重叠字符数\n",
    "        \n",
    "    Returns:\n",
    "        List[Dict]: 包含元数据的文本块列表\n",
    "    \"\"\"\n",
    "    chunks = []  # 初始化空列表来存储块\n",
    "    \n",
    "    # 以指定的块大小和重叠遍历文本\n",
    "    for i in range(0, len(text), chunk_size - overlap):\n",
    "        chunk_text = text[i:i + chunk_size]  # 提取文本块\n",
    "        \n",
    "        # 跳过非常小的块（少于 50 个字符）\n",
    "        if chunk_text and len(chunk_text.strip()) > 50:\n",
    "            # 创建元数据副本并添加块特定信息\n",
    "            chunk_metadata = metadata.copy()\n",
    "            chunk_metadata.update({\n",
    "                \"chunk_index\": len(chunks),  # 块的索引\n",
    "                \"start_char\": i,  # 块的起始字符索引\n",
    "                \"end_char\": i + len(chunk_text),  # 块的结束字符索引\n",
    "                \"is_summary\": False  # 标志表示这不是摘要\n",
    "            })\n",
    "            \n",
    "            # 将块及其元数据追加到列表中\n",
    "            chunks.append({\n",
    "                \"text\": chunk_text,\n",
    "                \"metadata\": chunk_metadata\n",
    "            })\n",
    "    \n",
    "    return chunks  # 返回包含元数据的块列表"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 简单向量存储实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleVectorStore:\n",
    "    \"\"\"\n",
    "    使用 NumPy 的简单向量存储实现。\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.vectors = []  # 存储向量嵌入的列表\n",
    "        self.texts = []  # 存储文本内容的列表\n",
    "        self.metadata = []  # 存储元数据的列表\n",
    "    \n",
    "    def add_item(self, text, embedding, metadata=None):\n",
    "        \"\"\"\n",
    "        向向量存储中添加项目。\n",
    "        \n",
    "        Args:\n",
    "            text (str): 文本内容\n",
    "            embedding (List[float]): 向量嵌入\n",
    "            metadata (Dict, optional): 附加元数据\n",
    "        \"\"\"\n",
    "        self.vectors.append(np.array(embedding))  # 将嵌入作为 numpy 数组追加\n",
    "        self.texts.append(text)  # 追加文本内容\n",
    "        self.metadata.append(metadata or {})  # 追加元数据或空字典（如果为 None）\n",
    "    \n",
    "    def similarity_search(self, query_embedding, k=5, filter_func=None):\n",
    "        \"\"\"\n",
    "        查找与查询嵌入最相似的项目。\n",
    "        \n",
    "        Args:\n",
    "            query_embedding (List[float]): 查询嵌入向量\n",
    "            k (int): 要返回的结果数量\n",
    "            filter_func (callable, optional): 过滤结果的函数\n",
    "            \n",
    "        Returns:\n",
    "            List[Dict]: 前 k 个最相似的项目\n",
    "        \"\"\"\n",
    "        if not self.vectors:\n",
    "            return []  # 如果没有向量，返回空列表\n",
    "        \n",
    "        # 将查询嵌入转换为 numpy 数组\n",
    "        query_vector = np.array(query_embedding)\n",
    "        \n",
    "        # 使用余弦相似度计算相似性\n",
    "        similarities = []\n",
    "        for i, vector in enumerate(self.vectors):\n",
    "            # 如果不通过过滤器则跳过\n",
    "            if filter_func and not filter_func(self.metadata[i]):\n",
    "                continue\n",
    "                \n",
    "            # 计算余弦相似度\n",
    "            similarity = np.dot(query_vector, vector) / (np.linalg.norm(query_vector) * np.linalg.norm(vector))\n",
    "            similarities.append((i, similarity))  # 追加索引和相似度分数\n",
    "        \n",
    "        # 按相似度排序（降序）\n",
    "        similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        # 返回前 k 个结果\n",
    "        results = []\n",
    "        for i in range(min(k, len(similarities))):\n",
    "            idx, score = similarities[i]\n",
    "            results.append({\n",
    "                \"text\": self.texts[idx],  # 添加文本内容\n",
    "                \"metadata\": self.metadata[idx],  # 添加元数据\n",
    "                \"similarity\": float(score)  # 添加相似度分数\n",
    "            })\n",
    "        \n",
    "        return results  # 返回前 k 个结果列表"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建嵌入向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embeddings(texts, model=\"BAAI/bge-en-icl\"):\n",
    "    \"\"\"\n",
    "    为给定的文本创建嵌入向量。\n",
    "    \n",
    "    Args:\n",
    "        texts (List[str]): 输入文本\n",
    "        model (str): 嵌入模型名称\n",
    "        \n",
    "    Returns:\n",
    "        List[List[float]]: 嵌入向量\n",
    "    \"\"\"\n",
    "    # 处理空输入\n",
    "    if not texts:\n",
    "        return []\n",
    "        \n",
    "    # 如果需要，分批处理（OpenAI API 限制）\n",
    "    batch_size = 100\n",
    "    all_embeddings = []\n",
    "    \n",
    "    # 分批遍历输入文本\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch = texts[i:i + batch_size]  # 获取当前批次的文本\n",
    "        \n",
    "        # 为当前批次创建嵌入向量\n",
    "        response = client.embeddings.create(\n",
    "            model=model,\n",
    "            input=batch\n",
    "        )\n",
    "        \n",
    "        # 从响应中提取嵌入向量\n",
    "        batch_embeddings = [item.embedding for item in response.data]\n",
    "        all_embeddings.extend(batch_embeddings)  # 将批次嵌入向量添加到列表中\n",
    "    \n",
    "    return all_embeddings  # 返回所有嵌入向量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 摘要生成函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_page_summary(page_text):\n",
    "    \"\"\"\n",
    "    生成页面的简洁摘要。\n",
    "    \n",
    "    Args:\n",
    "        page_text (str): 页面的文本内容\n",
    "        \n",
    "    Returns:\n",
    "        str: 生成的摘要\n",
    "    \"\"\"\n",
    "    # 定义指导摘要模型的系统提示\n",
    "    system_prompt = \"\"\"您是一个专业的摘要系统。\n",
    "    为提供的文本创建详细摘要。\n",
    "    专注于捕获主要主题、关键信息和重要事实。\n",
    "    您的摘要应该足够全面以理解页面包含的内容，\n",
    "    但比原文更简洁。\"\"\"\n",
    "\n",
    "    # 如果输入文本超过最大令牌限制，则截断\n",
    "    max_tokens = 6000\n",
    "    truncated_text = page_text[:max_tokens] if len(page_text) > max_tokens else page_text\n",
    "\n",
    "    # 向 OpenAI API 发出请求以生成摘要\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"meta-llama/Llama-3.2-3B-Instruct\",  # 指定要使用的模型\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},  # 指导助手的系统消息\n",
    "            {\"role\": \"user\", \"content\": f\"请总结这段文本：\\n\\n{truncated_text}\"}  # 包含要总结文本的用户消息\n",
    "        ],\n",
    "        temperature=0.3  # 设置响应生成的温度\n",
    "    )\n",
    "    \n",
    "    # 返回生成的摘要内容\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分层文档处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_document_hierarchically(pdf_path, chunk_size=1000, chunk_overlap=200):\n",
    "    \"\"\"\n",
    "    将文档处理为分层索引。\n",
    "    \n",
    "    Args:\n",
    "        pdf_path (str): PDF 文件路径\n",
    "        chunk_size (int): 每个详细块的大小\n",
    "        chunk_overlap (int): 块之间的重叠\n",
    "        \n",
    "    Returns:\n",
    "        Tuple[SimpleVectorStore, SimpleVectorStore]: 摘要和详细向量存储\n",
    "    \"\"\"\n",
    "    # 从 PDF 中提取页面\n",
    "    pages = extract_text_from_pdf(pdf_path)\n",
    "    \n",
    "    # 为每个页面创建摘要\n",
    "    print(\"正在生成页面摘要...\")\n",
    "    summaries = []\n",
    "    for i, page in enumerate(pages):\n",
    "        print(f\"正在总结第 {i+1}/{len(pages)} 页...\")\n",
    "        summary_text = generate_page_summary(page[\"text\"])\n",
    "        \n",
    "        # 创建摘要元数据\n",
    "        summary_metadata = page[\"metadata\"].copy()\n",
    "        summary_metadata.update({\"is_summary\": True})\n",
    "        \n",
    "        # 将摘要文本和元数据追加到摘要列表中\n",
    "        summaries.append({\n",
    "            \"text\": summary_text,\n",
    "            \"metadata\": summary_metadata\n",
    "        })\n",
    "    \n",
    "    # 为每个页面创建详细块\n",
    "    detailed_chunks = []\n",
    "    for page in pages:\n",
    "        # 对页面文本进行分块\n",
    "        page_chunks = chunk_text(\n",
    "            page[\"text\"], \n",
    "            page[\"metadata\"], \n",
    "            chunk_size, \n",
    "            chunk_overlap\n",
    "        )\n",
    "        # 用当前页面的块扩展 detailed_chunks 列表\n",
    "        detailed_chunks.extend(page_chunks)\n",
    "    \n",
    "    print(f\"创建了 {len(detailed_chunks)} 个详细块\")\n",
    "    \n",
    "    # 为摘要创建嵌入向量\n",
    "    print(\"正在为摘要创建嵌入向量...\")\n",
    "    summary_texts = [summary[\"text\"] for summary in summaries]\n",
    "    summary_embeddings = create_embeddings(summary_texts)\n",
    "    \n",
    "    # 为详细块创建嵌入向量\n",
    "    print(\"正在为详细块创建嵌入向量...\")\n",
    "    chunk_texts = [chunk[\"text\"] for chunk in detailed_chunks]\n",
    "    chunk_embeddings = create_embeddings(chunk_texts)\n",
    "    \n",
    "    # 创建向量存储\n",
    "    summary_store = SimpleVectorStore()\n",
    "    detailed_store = SimpleVectorStore()\n",
    "    \n",
    "    # 将摘要添加到摘要存储\n",
    "    for i, summary in enumerate(summaries):\n",
    "        summary_store.add_item(\n",
    "            text=summary[\"text\"],\n",
    "            embedding=summary_embeddings[i],\n",
    "            metadata=summary[\"metadata\"]\n",
    "        )\n",
    "    \n",
    "    # 将块添加到详细存储\n",
    "    for i, chunk in enumerate(detailed_chunks):\n",
    "        detailed_store.add_item(\n",
    "            text=chunk[\"text\"],\n",
    "            embedding=chunk_embeddings[i],\n",
    "            metadata=chunk[\"metadata\"]\n",
    "        )\n",
    "    \n",
    "    print(f\"创建了包含 {len(summaries)} 个摘要和 {len(detailed_chunks)} 个块的向量存储\")\n",
    "    return summary_store, detailed_store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分层检索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_hierarchically(query, summary_store, detailed_store, k_summaries=3, k_chunks=5):\n",
    "    \"\"\"\n",
    "    使用分层索引检索信息。\n",
    "    \n",
    "    Args:\n",
    "        query (str): 用户查询\n",
    "        summary_store (SimpleVectorStore): 文档摘要存储\n",
    "        detailed_store (SimpleVectorStore): 详细块存储\n",
    "        k_summaries (int): 要检索的摘要数量\n",
    "        k_chunks (int): 每个摘要要检索的块数量\n",
    "        \n",
    "    Returns:\n",
    "        List[Dict]: 带有相关性分数的检索块\n",
    "    \"\"\"\n",
    "    print(f\"正在对查询进行分层检索：{query}\")\n",
    "    \n",
    "    # 创建查询嵌入向量\n",
    "    query_embedding = create_embeddings(query)\n",
    "    \n",
    "    # 首先，检索相关摘要\n",
    "    summary_results = summary_store.similarity_search(\n",
    "        query_embedding, \n",
    "        k=k_summaries\n",
    "    )\n",
    "    \n",
    "    print(f\"检索到 {len(summary_results)} 个相关摘要\")\n",
    "    \n",
    "    # 从相关摘要中收集页面\n",
    "    relevant_pages = [result[\"metadata\"][\"page\"] for result in summary_results]\n",
    "    \n",
    "    # 创建过滤函数，只保留来自相关页面的块\n",
    "    def page_filter(metadata):\n",
    "        return metadata[\"page\"] in relevant_pages\n",
    "    \n",
    "    # 然后，仅从这些相关页面检索详细块\n",
    "    detailed_results = detailed_store.similarity_search(\n",
    "        query_embedding, \n",
    "        k=k_chunks * len(relevant_pages),\n",
    "        filter_func=page_filter\n",
    "    )\n",
    "    \n",
    "    print(f\"从相关页面检索到 {len(detailed_results)} 个详细块\")\n",
    "    \n",
    "    # 为每个结果添加它来自哪个摘要/页面\n",
    "    for result in detailed_results:\n",
    "        page = result[\"metadata\"][\"page\"]\n",
    "        matching_summaries = [s for s in summary_results if s[\"metadata\"][\"page\"] == page]\n",
    "        if matching_summaries:\n",
    "            result[\"summary\"] = matching_summaries[0][\"text\"]\n",
    "    \n",
    "    return detailed_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 响应生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(query, retrieved_chunks):\n",
    "    \"\"\"\n",
    "    基于检索到的块生成响应。\n",
    "    \n",
    "    Args:\n",
    "        query (str): 用户查询\n",
    "        retrieved_chunks (List[Dict]): 检索到的文本块\n",
    "        \n",
    "    Returns:\n",
    "        str: 生成的响应\n",
    "    \"\"\"\n",
    "    # 构建上下文\n",
    "    context_parts = []\n",
    "    for chunk in retrieved_chunks:\n",
    "        # 包含页面信息和摘要（如果可用）\n",
    "        page_info = f\"页面 {chunk['metadata']['page']}\"\n",
    "        if 'summary' in chunk:\n",
    "            context_parts.append(f\"[{page_info} - 摘要: {chunk['summary'][:200]}...]\")\n",
    "        context_parts.append(f\"[{page_info}] {chunk['text']}\")\n",
    "    \n",
    "    context = \"\\n\\n\".join(context_parts)\n",
    "    \n",
    "    # 限制上下文长度\n",
    "    max_context = 12000\n",
    "    if len(context) > max_context:\n",
    "        context = context[:max_context] + \"... [已截断]\"\n",
    "    \n",
    "    # 生成响应\n",
    "    system_message = \"\"\"您是一个有用的 AI 助手。基于提供的上下文回答用户的问题。\n",
    "上下文包含来自不同页面的信息，每个部分都标有页面号。\n",
    "在您的答案中引用特定页面，并确保您的响应准确且有帮助。\"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"meta-llama/Llama-3.2-3B-Instruct\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_message},\n",
    "            {\"role\": \"user\", \"content\": f\"上下文：\\n{context}\\n\\n问题：{query}\"}\n",
    "        ],\n",
    "        temperature=0.2\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 完整的分层检索 RAG 流水线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hierarchical_rag(query, pdf_path, chunk_size=1000, chunk_overlap=200, \n",
    "                    k_summaries=3, k_chunks=5, regenerate=False):\n",
    "    \"\"\"\n",
    "    完整的分层 RAG 流水线。\n",
    "    \n",
    "    Args:\n",
    "        query (str): 用户查询\n",
    "        pdf_path (str): PDF 文档路径\n",
    "        chunk_size (int): 每个详细块的大小\n",
    "        chunk_overlap (int): 块之间的重叠\n",
    "        k_summaries (int): 要检索的摘要数量\n",
    "        k_chunks (int): 每个摘要要检索的块数量\n",
    "        regenerate (bool): 是否重新生成向量存储\n",
    "        \n",
    "    Returns:\n",
    "        Dict: 包括响应和检索块的结果\n",
    "    \"\"\"\n",
    "    # 为缓存创建存储文件名\n",
    "    summary_store_file = f\"{os.path.basename(pdf_path)}_summary_store.pkl\"\n",
    "    detailed_store_file = f\"{os.path.basename(pdf_path)}_detailed_store.pkl\"\n",
    "    \n",
    "    # 如果需要，处理文档并创建存储\n",
    "    if regenerate or not os.path.exists(summary_store_file) or not os.path.exists(detailed_store_file):\n",
    "        print(\"正在处理文档并创建向量存储...\")\n",
    "        # 处理文档以创建分层索引和向量存储\n",
    "        summary_store, detailed_store = process_document_hierarchically(\n",
    "            pdf_path, chunk_size, chunk_overlap\n",
    "        )\n",
    "        \n",
    "        # 将摘要存储保存到文件以供将来使用\n",
    "        with open(summary_store_file, 'wb') as f:\n",
    "            pickle.dump(summary_store, f)\n",
    "        \n",
    "        # 将详细存储保存到文件以供将来使用\n",
    "        with open(detailed_store_file, 'wb') as f:\n",
    "            pickle.dump(detailed_store, f)\n",
    "    else:\n",
    "        # 从文件加载现有的摘要存储\n",
    "        print(\"正在加载现有的向量存储...\")\n",
    "        with open(summary_store_file, 'rb') as f:\n",
    "            summary_store = pickle.load(f)\n",
    "        \n",
    "        # 从文件加载现有的详细存储\n",
    "        with open(detailed_store_file, 'rb') as f:\n",
    "            detailed_store = pickle.load(f)\n",
    "    \n",
    "    # 使用查询分层检索相关块\n",
    "    retrieved_chunks = retrieve_hierarchically(\n",
    "        query, summary_store, detailed_store, k_summaries, k_chunks\n",
    "    )\n",
    "    \n",
    "    # 基于检索到的块生成响应\n",
    "    response = generate_response(query, retrieved_chunks)\n",
    "    \n",
    "    # 返回包括查询、响应、检索块以及摘要和详细块计数的结果\n",
    "    return {\n",
    "        \"query\": query,\n",
    "        \"response\": response,\n",
    "        \"retrieved_chunks\": retrieved_chunks,\n",
    "        \"summary_count\": len(summary_store.texts),\n",
    "        \"detailed_count\": len(detailed_store.texts)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 用于比较的标准（非分层）RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_rag(query, pdf_path, chunk_size=1000, chunk_overlap=200, k=15):\n",
    "    \"\"\"\n",
    "    不使用分层检索的标准 RAG 流水线。\n",
    "    \n",
    "    Args:\n",
    "        query (str): 用户查询\n",
    "        pdf_path (str): PDF 文档路径\n",
    "        chunk_size (int): 每个块的大小\n",
    "        chunk_overlap (int): 块之间的重叠\n",
    "        k (int): 要检索的块数量\n",
    "        \n",
    "    Returns:\n",
    "        Dict: 包括响应和检索块的结果\n",
    "    \"\"\"\n",
    "    # 从 PDF 文档中提取页面\n",
    "    pages = extract_text_from_pdf(pdf_path)\n",
    "    \n",
    "    # 直接从所有页面创建块\n",
    "    chunks = []\n",
    "    for page in pages:\n",
    "        # 对页面文本进行分块\n",
    "        page_chunks = chunk_text(\n",
    "            page[\"text\"], \n",
    "            page[\"metadata\"], \n",
    "            chunk_size, \n",
    "            chunk_overlap\n",
    "        )\n",
    "        # 用当前页面的块扩展块列表\n",
    "        chunks.extend(page_chunks)\n",
    "    \n",
    "    print(f\"为标准 RAG 创建了 {len(chunks)} 个块\")\n",
    "    \n",
    "    # 创建向量存储来保存块\n",
    "    store = SimpleVectorStore()\n",
    "    \n",
    "    # 为块创建嵌入向量\n",
    "    print(\"正在为块创建嵌入向量...\")\n",
    "    texts = [chunk[\"text\"] for chunk in chunks]\n",
    "    embeddings = create_embeddings(texts)\n",
    "    \n",
    "    # 将块添加到向量存储\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        store.add_item(\n",
    "            text=chunk[\"text\"],\n",
    "            embedding=embeddings[i],\n",
    "            metadata=chunk[\"metadata\"]\n",
    "        )\n",
    "    \n",
    "    # 为查询创建嵌入向量\n",
    "    query_embedding = create_embeddings(query)\n",
    "    \n",
    "    # 基于查询嵌入向量检索最相关的块\n",
    "    retrieved_chunks = store.similarity_search(query_embedding, k=k)\n",
    "    print(f\"使用标准 RAG 检索了 {len(retrieved_chunks)} 个块\")\n",
    "    \n",
    "    # 基于检索到的块生成响应\n",
    "    response = generate_response(query, retrieved_chunks)\n",
    "    \n",
    "    # 返回包括查询、响应和检索块的结果\n",
    "    return {\n",
    "        \"query\": query,\n",
    "        \"response\": response,\n",
    "        \"retrieved_chunks\": retrieved_chunks\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 评估函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_approaches(query, pdf_path, reference_answer=None):\n",
    "    \"\"\"\n",
    "    比较分层和标准 RAG 方法。\n",
    "    \n",
    "    Args:\n",
    "        query (str): 用户查询\n",
    "        pdf_path (str): PDF 文档路径\n",
    "        reference_answer (str, optional): 用于评估的参考答案\n",
    "        \n",
    "    Returns:\n",
    "        Dict: 比较结果\n",
    "    \"\"\"\n",
    "    print(f\"\\n=== 比较查询的 RAG 方法：{query} ===\")\n",
    "    \n",
    "    # 运行分层 RAG\n",
    "    print(\"\\n运行分层 RAG...\")\n",
    "    hierarchical_result = hierarchical_rag(query, pdf_path)\n",
    "    hier_response = hierarchical_result[\"response\"]\n",
    "    \n",
    "    # 运行标准 RAG\n",
    "    print(\"\\n运行标准 RAG...\")\n",
    "    standard_result = standard_rag(query, pdf_path)\n",
    "    std_response = standard_result[\"response\"]\n",
    "    \n",
    "    # 比较分层和标准 RAG 的结果\n",
    "    comparison = compare_responses(query, hier_response, std_response, reference_answer)\n",
    "    \n",
    "    # 返回包含比较结果的字典\n",
    "    return {\n",
    "        \"query\": query,  # 原始查询\n",
    "        \"hierarchical_response\": hier_response,  # 分层 RAG 的响应\n",
    "        \"standard_response\": std_response,  # 标准 RAG 的响应\n",
    "        \"reference_answer\": reference_answer,  # 用于评估的参考答案\n",
    "        \"comparison\": comparison,  # 比较分析\n",
    "        \"hierarchical_chunks_count\": len(hierarchical_result[\"retrieved_chunks\"]),  # 分层 RAG 检索的块数量\n",
    "        \"standard_chunks_count\": len(standard_result[\"retrieved_chunks\"])  # 标准 RAG 检索的块数量\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_responses(query, hierarchical_response, standard_response, reference=None):\n",
    "    \"\"\"\n",
    "    比较分层和标准 RAG 的响应。\n",
    "    \n",
    "    Args:\n",
    "        query (str): 用户查询\n",
    "        hierarchical_response (str): 分层 RAG 的响应\n",
    "        standard_response (str): 标准 RAG 的响应\n",
    "        reference (str, optional): 参考答案\n",
    "        \n",
    "    Returns:\n",
    "        str: 比较分析\n",
    "    \"\"\"\n",
    "    # 定义指导模型如何评估响应的系统提示\n",
    "    system_prompt = \"\"\"您是信息检索系统的专家评估员。\n",
    "比较对同一查询的两个响应，一个使用分层检索生成，\n",
    "另一个使用标准检索生成。\n",
    "\n",
    "基于以下方面评估它们：\n",
    "1. 准确性：哪个响应提供了更多事实正确的信息？\n",
    "2. 全面性：哪个响应更好地涵盖了查询的所有方面？\n",
    "3. 连贯性：哪个响应具有更好的逻辑流程和组织？\n",
    "4. 页面引用：任一响应是否更好地使用了页面引用？\n",
    "\n",
    "在分析每种方法的优缺点时要具体。\"\"\"\n",
    "\n",
    "    # 创建包含查询和两个响应的用户提示\n",
    "    user_prompt = f\"\"\"查询：{query}\n",
    "\n",
    "分层 RAG 的响应：\n",
    "{hierarchical_response}\n",
    "\n",
    "标准 RAG 的响应：\n",
    "{standard_response}\"\"\"\n",
    "\n",
    "    # 如果提供了参考答案，将其包含在用户提示中\n",
    "    if reference:\n",
    "        user_prompt += f\"\"\"\n",
    "\n",
    "参考答案：\n",
    "{reference}\"\"\"\n",
    "\n",
    "    # 向用户提示添加最终指令\n",
    "    user_prompt += \"\"\"\n",
    "\n",
    "请提供这两个响应的详细比较，突出哪种方法表现更好以及原因。\"\"\"\n",
    "\n",
    "    # 向 OpenAI API 发出请求以生成比较分析\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"meta-llama/Llama-3.2-3B-Instruct\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},  # 指导助手的系统消息\n",
    "            {\"role\": \"user\", \"content\": user_prompt}  # 包含查询和响应的用户消息\n",
    "        ],\n",
    "        temperature=0  # 设置响应生成的温度\n",
    "    )\n",
    "    \n",
    "    # 返回生成的比较分析\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 示例使用和评估\n",
    "\n",
    "以下代码演示了如何使用分层 RAG 系统并与标准 RAG 进行比较。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 示例使用\n",
    "if __name__ == \"__main__\":\n",
    "    # PDF 文档路径\n",
    "    pdf_path = \"data/AI_Information.pdf\"\n",
    "    \n",
    "    # 测试查询\n",
    "    query = \"Transformer 模型在自然语言处理中的关键应用有哪些？\"\n",
    "    \n",
    "    # 运行分层 RAG\n",
    "    result = hierarchical_rag(query, pdf_path)\n",
    "    \n",
    "    print(f\"查询：{result['query']}\")\n",
    "    print(f\"响应：{result['response']}\")\n",
    "    print(f\"检索的块数量：{len(result['retrieved_chunks'])}\")\n",
    "    print(f\"摘要数量：{result['summary_count']}\")\n",
    "    print(f\"详细块数量：{result['detailed_count']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 总结\n",
    "\n",
    "分层索引 RAG 通过以下方式改进了传统的检索方法：\n",
    "\n",
    "1. **两层检索策略**：首先在摘要级别进行粗粒度搜索，然后在详细块级别进行细粒度搜索\n",
    "2. **上下文保持**：通过页面级摘要保持更大的上下文，同时仍能访问具体细节\n",
    "3. **效率提升**：通过首先过滤相关页面来减少搜索空间\n",
    "4. **更好的相关性**：通过分层过滤提高检索内容的相关性\n",
    "\n",
    "这种方法特别适用于：\n",
    "- 大型文档集合\n",
    "- 需要上下文感知的查询\n",
    "- 多主题文档\n",
    "- 需要在概述和细节之间平衡的应用\n",
    "\n",
    "分层索引代表了 RAG 系统设计中的重要进步，为更智能、更高效的信息检索提供了框架。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}