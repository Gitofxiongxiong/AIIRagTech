{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "source": [
    "# 融合检索：结合向量搜索和关键词搜索 (Fusion Retrieval: Combining Vector and Keyword Search)\n",
    "\n",
    "在这个笔记本中，我实现了一个融合检索系统，该系统结合了语义向量搜索和基于关键词的 BM25 检索的优势。这种方法通过捕获概念相似性和精确关键词匹配来提高检索质量。\n",
    "\n",
    "## 为什么融合检索很重要\n",
    "\n",
    "传统的 RAG 系统通常仅依赖向量搜索，但这有其局限性：\n",
    "\n",
    "- 向量搜索在语义相似性方面表现出色，但可能错过精确的关键词匹配\n",
    "- 关键词搜索对特定术语很有效，但缺乏语义理解\n",
    "- 不同的查询在不同的检索方法下表现更好\n",
    "\n",
    "融合检索通过以下方式为我们提供了两全其美的解决方案：\n",
    "\n",
    "- 同时执行基于向量和基于关键词的检索\n",
    "- 对每种方法的分数进行标准化\n",
    "- 使用加权公式将它们结合起来\n",
    "- 基于组合分数对文档进行排名"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 设置环境\n",
    "我们首先导入必要的库。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from rank_bm25 import BM25Okapi\n",
    "import fitz\n",
    "from openai import OpenAI\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 设置 OpenAI API 客户端\n",
    "我们初始化 OpenAI 客户端来生成嵌入向量和响应。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用基础 URL 和 API 密钥初始化 OpenAI 客户端\n",
    "client = OpenAI(\n",
    "    base_url=\"https://api.studio.nebius.com/v1/\",\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\")  # 从环境变量中获取 API 密钥\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 文档处理函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"\n",
    "    从 PDF 文件中提取文本内容。\n",
    "    \n",
    "    参数:\n",
    "        pdf_path (str): PDF 文件的路径\n",
    "        \n",
    "    返回:\n",
    "        str: 提取的文本内容\n",
    "    \"\"\"\n",
    "    print(f\"从 {pdf_path} 提取文本...\")  # 打印正在处理的 PDF 路径\n",
    "    pdf_document = fitz.open(pdf_path)  # 使用 PyMuPDF 打开 PDF 文件\n",
    "    text = \"\"  # 初始化一个空字符串来存储提取的文本\n",
    "    \n",
    "    # 遍历 PDF 中的每一页\n",
    "    for page_num in range(pdf_document.page_count):\n",
    "        page = pdf_document[page_num]  # 获取页面对象\n",
    "        text += page.get_text()  # 从页面提取文本并追加到文本字符串中\n",
    "    \n",
    "    return text  # 返回提取的文本内容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text(text, chunk_size=1000, chunk_overlap=200):\n",
    "    \"\"\"\n",
    "    将文本分割成重叠的块。\n",
    "    \n",
    "    参数:\n",
    "        text (str): 要分块的输入文本\n",
    "        chunk_size (int): 每个块的字符数大小\n",
    "        chunk_overlap (int): 块之间的重叠字符数\n",
    "        \n",
    "    返回:\n",
    "        List[Dict]: 包含文本和元数据的块列表\n",
    "    \"\"\"\n",
    "    chunks = []  # 初始化一个空列表来存储块\n",
    "    \n",
    "    # 按指定的块大小和重叠遍历文本\n",
    "    for i in range(0, len(text), chunk_size - chunk_overlap):\n",
    "        chunk = text[i:i + chunk_size]  # 提取指定大小的块\n",
    "        if chunk:  # 确保我们不添加空块\n",
    "            chunk_data = {\n",
    "                \"text\": chunk,  # 块文本\n",
    "                \"metadata\": {\n",
    "                    \"start_char\": i,  # 块的起始字符索引\n",
    "                    \"end_char\": i + len(chunk)  # 块的结束字符索引\n",
    "                }\n",
    "            }\n",
    "            chunks.append(chunk_data)  # 将块数据添加到列表中\n",
    "    \n",
    "    print(f\"创建了 {len(chunks)} 个文本块\")  # 打印创建的块数量\n",
    "    return chunks  # 返回块列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    通过移除多余的空白和特殊字符来清理文本。\n",
    "    \n",
    "    参数:\n",
    "        text (str): 输入文本\n",
    "        \n",
    "    返回:\n",
    "        str: 清理后的文本\n",
    "    \"\"\"\n",
    "    # 将多个空白字符（包括换行符和制表符）替换为单个空格\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    # 通过将制表符和换行符替换为空格来修复常见的 OCR 问题\n",
    "    text = text.replace('\\\\t', ' ')\n",
    "    text = text.replace('\\\\n', ' ')\n",
    "    \n",
    "    # 移除任何前导或尾随空白，并确保单词之间只有单个空格\n",
    "    text = ' '.join(text.split())\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建我们的向量存储"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embeddings(texts, model=\"BAAI/bge-en-icl\"):\n",
    "    \"\"\"\n",
    "    为给定的文本创建嵌入向量。\n",
    "    \n",
    "    参数:\n",
    "        texts (str or List[str]): 输入文本\n",
    "        model (str): 嵌入模型名称\n",
    "        \n",
    "    返回:\n",
    "        List[List[float]]: 嵌入向量\n",
    "    \"\"\"\n",
    "    # 处理字符串和列表输入\n",
    "    input_texts = texts if isinstance(texts, list) else [texts]\n",
    "    \n",
    "    # 如果需要，分批处理（OpenAI API 限制）\n",
    "    batch_size = 100\n",
    "    all_embeddings = []\n",
    "    \n",
    "    # 分批遍历输入文本\n",
    "    for i in range(0, len(input_texts), batch_size):\n",
    "        batch = input_texts[i:i + batch_size]  # 获取当前批次的文本\n",
    "        \n",
    "        # 为当前批次创建嵌入向量\n",
    "        response = client.embeddings.create(\n",
    "            model=model,\n",
    "            input=batch\n",
    "        )\n",
    "        \n",
    "        # 从响应中提取嵌入向量\n",
    "        batch_embeddings = [item.embedding for item in response.data]\n",
    "        all_embeddings.extend(batch_embeddings)  # 将批次嵌入向量添加到列表中\n",
    "    \n",
    "    # 如果输入是字符串，只返回第一个嵌入向量\n",
    "    if isinstance(texts, str):\n",
    "        return all_embeddings[0]\n",
    "    \n",
    "    # 否则返回所有嵌入向量\n",
    "    return all_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleVectorStore:\n",
    "    \"\"\"\n",
    "    使用 NumPy 的简单向量存储实现。\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.vectors = []  # 存储嵌入向量的列表\n",
    "        self.texts = []  # 存储文本内容的列表\n",
    "        self.metadata = []  # 存储元数据的列表\n",
    "    \n",
    "    def add_item(self, text, embedding, metadata=None):\n",
    "        \"\"\"\n",
    "        向向量存储中添加一个项目。\n",
    "        \n",
    "        参数:\n",
    "            text (str): 文本内容\n",
    "            embedding (List[float]): 嵌入向量\n",
    "            metadata (Dict, optional): 附加元数据\n",
    "        \"\"\"\n",
    "        self.vectors.append(np.array(embedding))  # 追加嵌入向量\n",
    "        self.texts.append(text)  # 追加文本内容\n",
    "        self.metadata.append(metadata or {})  # 追加元数据（如果为 None 则为空字典）\n",
    "    \n",
    "    def add_items(self, items, embeddings):\n",
    "        \"\"\"\n",
    "        向向量存储中添加多个项目。\n",
    "        \n",
    "        参数:\n",
    "            items (List[Dict]): 文本项目列表\n",
    "            embeddings (List[List[float]]): 嵌入向量列表\n",
    "        \"\"\"\n",
    "        for i, (item, embedding) in enumerate(zip(items, embeddings)):\n",
    "            self.add_item(\n",
    "                text=item[\"text\"],  # 从项目中提取文本\n",
    "                embedding=embedding,  # 使用对应的嵌入向量\n",
    "                metadata={**item.get(\"metadata\", {}), \"index\": i}  # 合并项目元数据和索引\n",
    "            )\n",
    "    \n",
    "    def similarity_search_with_scores(self, query_embedding, k=5):\n",
    "        \"\"\"\n",
    "        查找与查询嵌入向量最相似的项目并返回相似度分数。\n",
    "        \n",
    "        参数:\n",
    "            query_embedding (List[float]): 查询嵌入向量\n",
    "            k (int): 返回结果的数量\n",
    "            \n",
    "        返回:\n",
    "            List[Tuple[Dict, float]]: 前 k 个最相似的项目及其分数\n",
    "        \"\"\"\n",
    "        if not self.vectors:\n",
    "            return []  # 如果没有存储向量则返回空列表\n",
    "        \n",
    "        # 将查询嵌入向量转换为 numpy 数组\n",
    "        query_vector = np.array(query_embedding)\n",
    "        \n",
    "        # 使用余弦相似度计算相似性\n",
    "        similarities = []\n",
    "        for i, vector in enumerate(self.vectors):\n",
    "            similarity = cosine_similarity([query_vector], [vector])[0][0]  # 计算余弦相似度\n",
    "            similarities.append((i, similarity))  # 追加索引和相似度分数\n",
    "        \n",
    "        # 按相似度降序排序\n",
    "        similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        # 返回前 k 个结果及其分数\n",
    "        results = []\n",
    "        for i in range(min(k, len(similarities))):\n",
    "            idx, score = similarities[i]\n",
    "            results.append({\n",
    "                \"text\": self.texts[idx],  # 按索引检索文本\n",
    "                \"metadata\": self.metadata[idx],  # 按索引检索元数据\n",
    "                \"similarity\": float(score)  # 添加相似度分数\n",
    "            })\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def get_all_documents(self):\n",
    "        \"\"\"\n",
    "        获取存储中的所有文档。\n",
    "        \n",
    "        返回:\n",
    "            List[Dict]: 所有文档\n",
    "        \"\"\"\n",
    "        return [{\"text\": text, \"metadata\": meta} for text, meta in zip(self.texts, self.metadata)]  # 合并文本和元数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BM25 实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bm25_index(chunks):\n",
    "    \"\"\"\n",
    "    从给定的块创建 BM25 索引。\n",
    "    \n",
    "    参数:\n",
    "        chunks (List[Dict]): 文本块列表\n",
    "        \n",
    "    返回:\n",
    "        BM25Okapi: BM25 索引\n",
    "    \"\"\"\n",
    "    # 从每个块中提取文本\n",
    "    texts = [chunk[\"text\"] for chunk in chunks]\n",
    "    \n",
    "    # 通过按空白分割对每个文档进行分词\n",
    "    tokenized_docs = [text.split() for text in texts]\n",
    "    \n",
    "    # 使用分词文档创建 BM25 索引\n",
    "    bm25 = BM25Okapi(tokenized_docs)\n",
    "    \n",
    "    # 打印 BM25 索引中的文档数量\n",
    "    print(f\"创建了包含 {len(texts)} 个文档的 BM25 索引\")\n",
    "    \n",
    "    return bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bm25_search(bm25, chunks, query, k=5):\n",
    "    \"\"\"\n",
    "    使用查询搜索 BM25 索引。\n",
    "    \n",
    "    参数:\n",
    "        bm25 (BM25Okapi): BM25 索引\n",
    "        chunks (List[Dict]): 文本块列表\n",
    "        query (str): 查询字符串\n",
    "        k (int): 返回结果的数量\n",
    "        \n",
    "    返回:\n",
    "        List[Dict]: 前 k 个结果及其分数\n",
    "    \"\"\"\n",
    "    # 通过将查询分割成单个词来对查询进行分词\n",
    "    query_tokens = query.split()\n",
    "    \n",
    "    # 获取查询词对索引文档的 BM25 分数\n",
    "    scores = bm25.get_scores(query_tokens)\n",
    "    \n",
    "    # 初始化一个空列表来存储结果及其分数\n",
    "    results = []\n",
    "    \n",
    "    # 遍历分数和对应的块\n",
    "    for i, score in enumerate(scores):\n",
    "        # 创建元数据的副本以避免修改原始数据\n",
    "        metadata = chunks[i].get(\"metadata\", {}).copy()\n",
    "        # 向元数据添加索引\n",
    "        metadata[\"index\"] = i\n",
    "        \n",
    "        results.append({\n",
    "            \"text\": chunks[i][\"text\"],\n",
    "            \"metadata\": metadata,  # 添加带索引的元数据\n",
    "            \"bm25_score\": float(score)\n",
    "        })\n",
    "    \n",
    "    # 按 BM25 分数降序排序结果\n",
    "    results.sort(key=lambda x: x[\"bm25_score\"], reverse=True)\n",
    "    \n",
    "    # 返回前 k 个结果\n",
    "    return results[:k]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 融合检索函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fusion_retrieval(query, chunks, vector_store, bm25_index, k=5, alpha=0.5):\n",
    "    \"\"\"\n",
    "    执行结合基于向量和 BM25 搜索的融合检索。\n",
    "    \n",
    "    参数:\n",
    "        query (str): 查询字符串\n",
    "        chunks (List[Dict]): 原始文本块\n",
    "        vector_store (SimpleVectorStore): 向量存储\n",
    "        bm25_index (BM25Okapi): BM25 索引\n",
    "        k (int): 返回结果的数量\n",
    "        alpha (float): 向量分数的权重（0-1），其中 1-alpha 是 BM25 权重\n",
    "        \n",
    "    返回:\n",
    "        List[Dict]: 基于组合分数的前 k 个结果\n",
    "    \"\"\"\n",
    "    print(f\"对查询执行融合检索：{query}\")\n",
    "    \n",
    "    # 定义小的 epsilon 以避免除零\n",
    "    epsilon = 1e-8\n",
    "    \n",
    "    # 获取向量搜索结果\n",
    "    query_embedding = create_embeddings(query)  # 为查询创建嵌入向量\n",
    "    vector_results = vector_store.similarity_search_with_scores(query_embedding, k=len(chunks))  # 执行向量搜索\n",
    "    \n",
    "    # 获取 BM25 搜索结果\n",
    "    bm25_results = bm25_search(bm25_index, chunks, query, k=len(chunks))  # 执行 BM25 搜索\n",
    "    \n",
    "    # 创建字典将文档索引映射到分数\n",
    "    vector_scores_dict = {result[\"metadata\"][\"index\"]: result[\"similarity\"] for result in vector_results}\n",
    "    bm25_scores_dict = {result[\"metadata\"][\"index\"]: result[\"bm25_score\"] for result in bm25_results}\n",
    "    \n",
    "    # 确保所有文档都有两种方法的分数\n",
    "    all_docs = vector_store.get_all_documents()\n",
    "    combined_results = []\n",
    "    \n",
    "    for i, doc in enumerate(all_docs):\n",
    "        vector_score = vector_scores_dict.get(i, 0.0)  # 获取向量分数，如果未找到则为 0\n",
    "        bm25_score = bm25_scores_dict.get(i, 0.0)  # 获取 BM25 分数，如果未找到则为 0\n",
    "        combined_results.append({\n",
    "            \"text\": doc[\"text\"],\n",
    "            \"metadata\": doc[\"metadata\"],\n",
    "            \"vector_score\": vector_score,\n",
    "            \"bm25_score\": bm25_score,\n",
    "            \"index\": i\n",
    "        })\n",
    "    \n",
    "    # 将分数提取为数组\n",
    "    vector_scores = np.array([doc[\"vector_score\"] for doc in combined_results])\n",
    "    bm25_scores = np.array([doc[\"bm25_score\"] for doc in combined_results])\n",
    "    \n",
    "    # 标准化分数\n",
    "    norm_vector_scores = (vector_scores - np.min(vector_scores)) / (np.max(vector_scores) - np.min(vector_scores) + epsilon)\n",
    "    norm_bm25_scores = (bm25_scores - np.min(bm25_scores)) / (np.max(bm25_scores) - np.min(bm25_scores) + epsilon)\n",
    "    \n",
    "    # 计算组合分数\n",
    "    combined_scores = alpha * norm_vector_scores + (1 - alpha) * norm_bm25_scores\n",
    "    \n",
    "    # 将组合分数添加到结果中\n",
    "    for i, score in enumerate(combined_scores):\n",
    "        combined_results[i][\"combined_score\"] = float(score)\n",
    "    \n",
    "    # 按组合分数降序排序\n",
    "    combined_results.sort(key=lambda x: x[\"combined_score\"], reverse=True)\n",
    "    \n",
    "    # 返回前 k 个结果\n",
    "    top_results = combined_results[:k]\n",
    "    \n",
    "    print(f\"使用融合检索检索到 {len(top_results)} 个文档\")\n",
    "    return top_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 文档处理流水线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_document(pdf_path, chunk_size=1000, chunk_overlap=200):\n",
    "    \"\"\"\n",
    "    为融合检索处理文档。\n",
    "    \n",
    "    参数:\n",
    "        pdf_path (str): PDF 文件的路径\n",
    "        chunk_size (int): 每个块的字符数大小\n",
    "        chunk_overlap (int): 块之间的重叠字符数\n",
    "        \n",
    "    返回:\n",
    "        Tuple[List[Dict], SimpleVectorStore, BM25Okapi]: 块、向量存储和 BM25 索引\n",
    "    \"\"\"\n",
    "    # 从 PDF 文件提取文本\n",
    "    text = extract_text_from_pdf(pdf_path)\n",
    "    \n",
    "    # 清理提取的文本以移除多余的空白和特殊字符\n",
    "    cleaned_text = clean_text(text)\n",
    "    \n",
    "    # 将清理后的文本分割成重叠的块\n",
    "    chunks = chunk_text(cleaned_text, chunk_size, chunk_overlap)\n",
    "    \n",
    "    # 从每个块中提取文本内容用于嵌入创建\n",
    "    chunk_texts = [chunk[\"text\"] for chunk in chunks]\n",
    "    print(\"为块创建嵌入向量...\")\n",
    "    \n",
    "    # 为块文本创建嵌入向量\n",
    "    embeddings = create_embeddings(chunk_texts)\n",
    "    \n",
    "    # 初始化向量存储\n",
    "    vector_store = SimpleVectorStore()\n",
    "    \n",
    "    # 将块及其嵌入向量添加到向量存储中\n",
    "    vector_store.add_items(chunks, embeddings)\n",
    "    print(f\"向向量存储添加了 {len(chunks)} 个项目\")\n",
    "    \n",
    "    # 从块创建 BM25 索引\n",
    "    bm25_index = create_bm25_index(chunks)\n",
    "    \n",
    "    # 返回块、向量存储和 BM25 索引\n",
    "    return chunks, vector_store, bm25_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 响应生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(query, context):\n",
    "    \"\"\"\n",
    "    基于查询和上下文生成响应。\n",
    "    \n",
    "    参数:\n",
    "        query (str): 用户查询\n",
    "        context (str): 从检索文档中获得的上下文\n",
    "        \n",
    "    返回:\n",
    "        str: 生成的响应\n",
    "    \"\"\"\n",
    "    # 定义系统提示词来指导 AI 助手\n",
    "    system_prompt = \"\"\"你是一个有用的 AI 助手。基于提供的上下文回答用户的问题。\n",
    "    如果上下文不包含完全回答问题的相关信息，请承认这一限制。\"\"\"\n",
    "\n",
    "    # 使用上下文和查询格式化用户提示词\n",
    "    user_prompt = f\"\"\"上下文：\n",
    "    {context}\n",
    "\n",
    "    问题：{query}\n",
    "\n",
    "    请基于提供的上下文回答问题。\"\"\"\n",
    "\n",
    "    # 使用 OpenAI API 生成响应\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"meta-llama/Llama-3.2-3B-Instruct\",  # 指定要使用的模型\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},  # 指导助手的系统消息\n",
    "            {\"role\": \"user\", \"content\": user_prompt}  # 包含上下文和查询的用户消息\n",
    "        ],\n",
    "        temperature=0.1  # 设置响应生成的温度\n",
    "    )\n",
    "    \n",
    "    # 返回生成的响应\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 主要检索函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_with_fusion_rag(query, chunks, vector_store, bm25_index, k=5, alpha=0.5):\n",
    "    \"\"\"\n",
    "    使用融合 RAG 回答查询。\n",
    "    \n",
    "    参数:\n",
    "        query (str): 用户查询\n",
    "        chunks (List[Dict]): 文本块\n",
    "        vector_store (SimpleVectorStore): 向量存储\n",
    "        bm25_index (BM25Okapi): BM25 索引\n",
    "        k (int): 要检索的文档数量\n",
    "        alpha (float): 向量分数的权重\n",
    "        \n",
    "    返回:\n",
    "        Dict: 查询结果，包括检索的文档和响应\n",
    "    \"\"\"\n",
    "    # 使用融合检索方法检索文档\n",
    "    retrieved_docs = fusion_retrieval(query, chunks, vector_store, bm25_index, k=k, alpha=alpha)\n",
    "    \n",
    "    # 通过用分隔符连接检索文档的文本来格式化上下文\n",
    "    context = \"\\n\\n---\\n\\n\".join([doc[\"text\"] for doc in retrieved_docs])\n",
    "    \n",
    "    # 基于查询和格式化的上下文生成响应\n",
    "    response = generate_response(query, context)\n",
    "    \n",
    "    # 返回查询、检索的文档和生成的响应\n",
    "    return {\n",
    "        \"query\": query,\n",
    "        \"retrieved_documents\": retrieved_docs,\n",
    "        \"response\": response\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 比较检索方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_only_rag(query, vector_store, k=5):\n",
    "    \"\"\"\n",
    "    仅使用基于向量的 RAG 回答查询。\n",
    "    \n",
    "    参数:\n",
    "        query (str): 用户查询\n",
    "        vector_store (SimpleVectorStore): 向量存储\n",
    "        k (int): 要检索的文档数量\n",
    "        \n",
    "    返回:\n",
    "        Dict: 查询结果\n",
    "    \"\"\"\n",
    "    # 创建查询嵌入向量\n",
    "    query_embedding = create_embeddings(query)\n",
    "    \n",
    "    # 使用基于向量的相似性搜索检索文档\n",
    "    retrieved_docs = vector_store.similarity_search_with_scores(query_embedding, k=k)\n",
    "    \n",
    "    # 通过用分隔符连接检索文档的文本来格式化上下文\n",
    "    context = \"\\n\\n---\\n\\n\".join([doc[\"text\"] for doc in retrieved_docs])\n",
    "    \n",
    "    # 基于查询和格式化的上下文生成响应\n",
    "    response = generate_response(query, context)\n",
    "    \n",
    "    # 返回查询、检索的文档和生成的响应\n",
    "    return {\n",
    "        \"query\": query,\n",
    "        \"retrieved_documents\": retrieved_docs,\n",
    "        \"response\": response\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bm25_only_rag(query, chunks, bm25_index, k=5):\n",
    "    \"\"\"\n",
    "    仅使用基于 BM25 的 RAG 回答查询。\n",
    "    \n",
    "    参数:\n",
    "        query (str): 用户查询\n",
    "        chunks (List[Dict]): 文本块\n",
    "        bm25_index (BM25Okapi): BM25 索引\n",
    "        k (int): 要检索的文档数量\n",
    "        \n",
    "    返回:\n",
    "        Dict: 查询结果\n",
    "    \"\"\"\n",
    "    # 使用 BM25 搜索检索文档\n",
    "    retrieved_docs = bm25_search(bm25_index, chunks, query, k=k)\n",
    "    \n",
    "    # 通过用分隔符连接检索文档的文本来格式化上下文\n",
    "    context = \"\\n\\n---\\n\\n\".join([doc[\"text\"] for doc in retrieved_docs])\n",
    "    \n",
    "    # 基于查询和格式化的上下文生成响应\n",
    "    response = generate_response(query, context)\n",
    "    \n",
    "    # 返回查询、检索的文档和生成的响应\n",
    "    return {\n",
    "        \"query\": query,\n",
    "        \"retrieved_documents\": retrieved_docs,\n",
    "        \"response\": response\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 评估函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_retrieval_methods(query, chunks, vector_store, bm25_index, k=5, alpha=0.5, reference_answer=None):\n",
    "    \"\"\"\n",
    "    比较查询的不同检索方法。\n",
    "    \n",
    "    参数:\n",
    "        query (str): 用户查询\n",
    "        chunks (List[Dict]): 文本块\n",
    "        vector_store (SimpleVectorStore): 向量存储\n",
    "        bm25_index (BM25Okapi): BM25 索引\n",
    "        k (int): 要检索的文档数量\n",
    "        alpha (float): 融合检索中向量分数的权重\n",
    "        reference_answer (str, optional): 用于比较的参考答案\n",
    "        \n",
    "    返回:\n",
    "        Dict: 比较结果\n",
    "    \"\"\"\n",
    "    print(f\"\\n=== 比较查询的检索方法：{query} ===\\n\")\n",
    "    \n",
    "    # 运行仅向量 RAG\n",
    "    print(\"\\n运行仅向量 RAG...\")\n",
    "    vector_result = vector_only_rag(query, vector_store, k)\n",
    "    \n",
    "    # 运行仅 BM25 RAG\n",
    "    print(\"\\n运行仅 BM25 RAG...\")\n",
    "    bm25_result = bm25_only_rag(query, chunks, bm25_index, k)\n",
    "    \n",
    "    # 运行融合 RAG\n",
    "    print(\"\\n运行融合 RAG...\")\n",
    "    fusion_result = answer_with_fusion_rag(query, chunks, vector_store, bm25_index, k, alpha)\n",
    "    \n",
    "    # 比较不同检索方法的响应\n",
    "    print(\"\\n比较响应...\")\n",
    "    comparison = evaluate_responses(\n",
    "        query, \n",
    "        vector_result[\"response\"], \n",
    "        bm25_result[\"response\"], \n",
    "        fusion_result[\"response\"],\n",
    "        reference_answer\n",
    "    )\n",
    "    \n",
    "    # 返回比较结果\n",
    "    return {\n",
    "        \"query\": query,\n",
    "        \"vector_result\": vector_result,\n",
    "        \"bm25_result\": bm25_result,\n",
    "        \"fusion_result\": fusion_result,\n",
    "        \"comparison\": comparison\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_responses(query, vector_response, bm25_response, fusion_response, reference_answer=None):\n",
    "    \"\"\"\n",
    "    评估不同检索方法的响应。\n",
    "    \n",
    "    参数:\n",
    "        query (str): 用户查询\n",
    "        vector_response (str): 仅向量 RAG 的响应\n",
    "        bm25_response (str): 仅 BM25 RAG 的响应\n",
    "        fusion_response (str): 融合 RAG 的响应\n",
    "        reference_answer (str, optional): 参考答案\n",
    "        \n",
    "    返回:\n",
    "        str: 响应评估\n",
    "    \"\"\"\n",
    "    # 评估员的系统提示词，指导评估过程\n",
    "    system_prompt = \"\"\"你是 RAG 系统的专家评估员。比较三种不同检索方法的响应：\n",
    "    1. 基于向量的检索：使用语义相似性进行文档检索\n",
    "    2. BM25 关键词检索：使用关键词匹配进行文档检索\n",
    "    3. 融合检索：结合向量和关键词方法\n",
    "\n",
    "    基于以下标准评估响应：\n",
    "    - 与查询的相关性\n",
    "    - 事实正确性\n",
    "    - 全面性\n",
    "    - 清晰度和连贯性\"\"\"\n",
    "\n",
    "    # 包含查询和响应的用户提示词\n",
    "    user_prompt = f\"\"\"查询：{query}\n",
    "\n",
    "    基于向量的响应：\n",
    "    {vector_response}\n",
    "\n",
    "    BM25 关键词响应：\n",
    "    {bm25_response}\n",
    "\n",
    "    融合响应：\n",
    "    {fusion_response}\n",
    "    \"\"\"\n",
    "\n",
    "    # 如果提供了参考答案，将其添加到提示词中\n",
    "    if reference_answer:\n",
    "        user_prompt += f\"\"\"\n",
    "            参考答案：\n",
    "            {reference_answer}\n",
    "        \"\"\"\n",
    "\n",
    "    # 向用户提示词添加详细比较的指令\n",
    "    user_prompt += \"\"\"\n",
    "    请提供这三个响应的详细比较。哪种方法在这个查询上表现最好，为什么？\n",
    "    请具体说明每种方法在这个特定查询上的优缺点。\n",
    "    \"\"\"\n",
    "\n",
    "    # 使用 meta-llama/Llama-3.2-3B-Instruct 生成评估\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"meta-llama/Llama-3.2-3B-Instruct\",  # 指定要使用的模型\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},  # 指导评估员的系统消息\n",
    "            {\"role\": \"user\", \"content\": user_prompt}  # 包含查询和响应的用户消息\n",
    "        ],\n",
    "        temperature=0  # 设置响应生成的温度\n",
    "    )\n",
    "    \n",
    "    # 返回生成的评估内容\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 完整评估流水线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_fusion_retrieval(pdf_path, test_queries, reference_answers=None, k=5, alpha=0.5):\n",
    "    \"\"\"\n",
    "    评估融合检索与其他方法的比较。\n",
    "    \n",
    "    参数:\n",
    "        pdf_path (str): PDF 文件的路径\n",
    "        test_queries (List[str]): 测试查询列表\n",
    "        reference_answers (List[str], optional): 参考答案\n",
    "        k (int): 要检索的文档数量\n",
    "        alpha (float): 融合检索中向量分数的权重\n",
    "        \n",
    "    返回:\n",
    "        Dict: 评估结果\n",
    "    \"\"\"\n",
    "    print(\"=== 评估融合检索 ===\\n\")\n",
    "    \n",
    "    # 处理文档以提取文本、创建块并构建向量和 BM25 索引\n",
    "    chunks, vector_store, bm25_index = process_document(pdf_path)\n",
    "    \n",
    "    # 初始化一个列表来存储每个查询的结果\n",
    "    results = []\n",
    "    \n",
    "    # 遍历每个测试查询\n",
    "    for i, query in enumerate(test_queries):\n",
    "        print(f\"\\n\\n=== 评估查询 {i+1}/{len(test_queries)} ===\")\n",
    "        print(f\"查询：{query}\")\n",
    "        \n",
    "        # 如果可用，获取参考答案\n",
    "        reference = None\n",
    "        if reference_answers and i < len(reference_answers):\n",
    "            reference = reference_answers[i]\n",
    "        \n",
    "        # 比较当前查询的检索方法\n",
    "        comparison = compare_retrieval_methods(\n",
    "            query, \n",
    "            chunks, \n",
    "            vector_store, \n",
    "            bm25_index, \n",
    "            k=k, \n",
    "            alpha=alpha,\n",
    "            reference_answer=reference\n",
    "        )\n",
    "        \n",
    "        # 将比较结果追加到结果列表中\n",
    "        results.append(comparison)\n",
    "        \n",
    "        # 打印不同检索方法的响应\n",
    "        print(\"\\n=== 基于向量的响应 ===\")\n",
    "        print(comparison[\"vector_result\"][\"response\"])\n",
    "        \n",
    "        print(\"\\n=== BM25 响应 ===\")\n",
    "        print(comparison[\"bm25_result\"][\"response\"])\n",
    "        \n",
    "        print(\"\\n=== 融合响应 ===\")\n",
    "        print(comparison[\"fusion_result\"][\"response\"])\n",
    "        \n",
    "        print(\"\\n=== 比较 ===\")\n",
    "        print(comparison[\"comparison\"])\n",
    "    \n",
    "    # 生成融合检索性能的总体分析\n",
    "    overall_analysis = generate_overall_analysis(results)\n",
    "    \n",
    "    # 返回结果和总体分析\n",
    "    return {\n",
    "        \"results\": results,\n",
    "        \"overall_analysis\": overall_analysis\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_overall_analysis(results):\n",
    "    \"\"\"\n",
    "    生成融合检索的总体分析。\n",
    "    \n",
    "    参数:\n",
    "        results (List[Dict]): 评估查询的结果\n",
    "        \n",
    "    返回:\n",
    "        str: 总体分析\n",
    "    \"\"\"\n",
    "    # 指导评估过程的系统提示词\n",
    "    system_prompt = \"\"\"你是评估信息检索系统的专家。\n",
    "    基于多个测试查询，提供比较三种检索方法的总体分析：\n",
    "    1. 基于向量的检索（语义相似性）\n",
    "    2. BM25 关键词检索（关键词匹配）\n",
    "    3. 融合检索（两者结合）\n",
    "\n",
    "    重点关注：\n",
    "    1. 每种方法表现最佳的查询类型\n",
    "    2. 每种方法的总体优缺点\n",
    "    3. 融合检索如何平衡权衡\n",
    "    4. 何时使用每种方法的建议\"\"\"\n",
    "\n",
    "    # 为每个查询创建评估摘要\n",
    "    evaluations_summary = \"\"\n",
    "    for i, result in enumerate(results):\n",
    "        evaluations_summary += f\"查询 {i+1}：{result['query']}\\n\"\n",
    "        evaluations_summary += f\"比较摘要：{result['comparison'][:200]}...\\n\\n\"\n",
    "\n",
    "    # 包含评估摘要的用户提示词\n",
    "    user_prompt = f\"\"\"基于以下对 {len(results)} 个查询的不同检索方法评估，\n",
    "    提供比较这三种方法的总体分析：\n",
    "\n",
    "    {evaluations_summary}\n",
    "\n",
    "    请提供基于向量、BM25 和融合检索方法的全面分析，\n",
    "    突出融合检索何时以及为什么比单独方法提供优势。\"\"\"\n",
    "\n",
    "    # 使用 meta-llama/Llama-3.2-3B-Instruct 生成总体分析\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"meta-llama/Llama-3.2-3B-Instruct\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ],\n",
    "        temperature=0\n",
    "    )\n",
    "    \n",
    "    # 返回生成的分析内容\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 评估融合检索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 评估融合检索 ===\n",
      "\n",
      "从 data/AI_Information.pdf 提取文本...\n",
      "创建了 42 个文本块\n",
      "为块创建嵌入向量...\n",
      "向向量存储添加了 42 个项目\n",
      "创建了包含 42 个文档的 BM25 索引\n",
      "\n",
      "\n",
      "=== 评估查询 1/1 ===\n",
      "查询：transformer 模型在自然语言处理中的主要应用是什么？\n",
      "\n",
      "=== 比较查询的检索方法：transformer 模型在自然语言处理中的主要应用是什么？ ===\n",
      "\n",
      "\n",
      "运行仅向量 RAG...\n",
      "\n",
      "运行仅 BM25 RAG...\n",
      "\n",
      "运行融合 RAG...\n",
      "对查询执行融合检索：transformer 模型在自然语言处理中的主要应用是什么？\n",
      "使用融合检索检索到 5 个文档\n",
      "\n",
      "比较响应...\n",
      "\n",
      "=== 基于向量的响应 ===\n",
      "提供的上下文没有明确提到 transformer 模型在自然语言处理中的主要应用。然而，上下文确实提到了生成式对抗网络（GANs）和 transformers 是生成式 AI 模型的例子，可以创建原创内容，包括图像、文本和音乐。\n",
      "\n",
      "基于一般知识，transformer 模型在自然语言处理中广泛用于以下任务：\n",
      "\n",
      "1. 机器翻译\n",
      "2. 文本生成\n",
      "3. 情感分析\n",
      "4. 文本分类\n",
      "5. 语言建模\n",
      "\n",
      "这些模型在许多 NLP 任务中取得了最先进的结果，并已成为许多应用的热门选择。\n",
      "\n",
      "如果您正在寻找有关 transformer 模型在 NLP 中应用的更具体信息，我可以尝试提供更多一般信息或为您指出更多资源的方向。\n",
      "\n",
      "=== BM25 响应 ===\n",
      "提供的上下文没有明确提到 transformer 模型或它们在自然语言处理中的应用。上下文涵盖了深度学习、卷积神经网络、循环神经网络、自然语言处理和机器学习等各种主题，但没有具体讨论 transformer 模型。\n",
      "\n",
      "如果您正在寻找有关 transformer 模型的信息，我可以提供有关此主题的一般信息。Transformer 模型是一种神经网络架构，在机器翻译、文本生成和语言理解等自然语言处理任务中获得了广泛应用。它们在处理序列数据中的长程依赖关系方面特别有效，并已在许多 NLP 应用中被广泛采用。然而，这些信息在提供的上下文中并不存在。\n",
      "\n",
      "=== 融合响应 ===\n",
      "提供的上下文没有明确提到 transformer 模型在自然语言处理中的主要应用。然而，上下文确实提到了生成式对抗网络（GANs）和 transformers 是生成式 AI 模型的例子，可以创建原创内容，包括图像、文本和音乐。\n",
      "\n",
      "基于一般知识，transformer 模型在自然语言处理中广泛用于以下任务：\n",
      "\n",
      "1. 机器翻译\n",
      "2. 文本生成\n",
      "3. 情感分析\n",
      "4. 文本分类\n",
      "5. 语言建模\n",
      "\n",
      "这些模型在许多 NLP 任务中取得了最先进的结果，并已成为许多应用的热门选择。\n",
      "\n",
      "如果您正在寻找有关 transformer 模型在 NLP 中应用的更具体信息，我可以尝试提供更多一般信息或为您指出更多资源的方向。\n",
      "\n",
      "=== 比较 ===\n",
      "**基于向量、BM25 关键词和融合检索方法的比较**\n",
      "\n",
      "对于给定的查询\"transformer 模型在自然语言处理中的主要应用是什么？\"，我们可以基于相关性、事实正确性、全面性和清晰度/连贯性来评估响应。\n",
      "\n",
      "**相关性：**\n",
      "\n",
      "* 基于向量的响应：9/10（响应直接解决了查询，并提供了 transformer 模型在 NLP 中主要应用的全面列表。）\n",
      "* BM25 关键词响应：5/10（响应没有直接解决查询，因为它没有提到 transformer 模型或它们在 NLP 中的应用。）\n",
      "* 融合响应：9/10（响应直接回答了问题，并提供了 transformer 模型在 NLP 中主要应用的全面列表。）\n",
      "\n",
      "**事实正确性：**\n",
      "\n",
      "* 基于向量的响应：9/10（响应事实正确，并提供了 transformer 模型在 NLP 中主要应用的准确列表。）\n",
      "* BM25 关键词响应：8/10（响应一般正确，但没有提到 transformer 模型或它们在 NLP 中的应用。）\n",
      "* 融合响应：9/10（响应事实正确，并提供了 transformer 模型在 NLP 中主要应用的准确列表。）\n",
      "\n",
      "**全面性：**\n",
      "\n",
      "* 基于向量的响应：9/10（响应提供了 transformer 模型在 NLP 中主要应用的全面列表。）\n",
      "* BM25 关键词响应：4/10（响应没有提供任何关于 transformer 模型或它们在 NLP 中应用的信息。）\n",
      "* 融合响应：9/10（响应提供了 transformer 模型在 NLP 中主要应用的全面列表。）\n",
      "\n",
      "**清晰度和连贯性：**\n",
      "\n",
      "* 基于向量的响应：9/10（响应清晰、简洁且组织良好，易于理解 transformer 模型在 NLP 中的主要应用。）\n",
      "* BM25 关键词响应：6/10（响应清晰，但没有提到 transformer 模型或它们在 NLP 中的应用。）\n",
      "* 融合响应：9/10（响应清晰、简洁且组织良好，易于理解 transformer 模型在 NLP 中的主要应用。）\n",
      "\n",
      "**总体性能：**\n",
      "\n",
      "* 基于向量的响应：9/10\n",
      "* BM25 关键词响应：5.75/10\n",
      "* 融合响应：9/10\n",
      "\n",
      "基于评估，基于向量和融合检索方法在这个查询上表现最好。两种响应都提供了 transformer 模型在 NLP 中主要应用的全面列表，事实正确，清晰简洁。BM25 关键词响应没有直接解决查询，因为它没有提到 transformer 模型或它们在 NLP 中的应用。\n",
      "\n",
      "\n",
      "=== 总体分析 ===\n",
      "\n",
      "**总体分析：基于向量、BM25 和融合检索方法**\n",
      "\n",
      "在这个分析中，我们将评估三种检索方法的性能：基于向量、BM25 关键词和融合检索。我们将检查它们的优缺点、在特定查询类型上的性能，以及融合检索如何平衡权衡。\n",
      "\n",
      "**查询 1：transformer 模型在自然语言处理中的主要应用是什么？**\n",
      "\n",
      "对于这个查询，我们可以评估三种方法的性能如下：\n",
      "\n",
      "1. **基于向量的检索（语义相似性）**：这种方法适合需要理解查询和文档语义含义的查询。在这种情况下，查询询问 transformer 模型的主要应用，这意味着需要语义理解。基于向量的方法可能表现良好，因为它可以捕获查询和文档的细微差别。\n",
      "\n",
      "性能：9/10\n",
      "\n",
      "2. **BM25 关键词检索（关键词匹配）**：这种方法适合需要精确关键词匹配的查询。在这种情况下，查询询问 transformer 模型的主要应用，这意味着需要精确关键词匹配。然而，查询也询问主要应用，这可能需要对文档有更细致的理解。\n",
      "\n",
      "性能：6/10\n",
      "\n",
      "3. **融合检索（两者结合）**：这种方法结合了基于向量和 BM25 关键词检索的优势。通过使用两种方法的组合，融合检索可以捕获查询的语义含义和精确关键词匹配。\n",
      "\n",
      "性能：9/10\n",
      "\n",
      "**每种方法的总体优缺点**\n",
      "\n",
      "1. **基于向量的检索（语义相似性）**：\n",
      "\t* 优势：可以捕获查询和文档的细微差别，适合需要语义理解的查询。\n",
      "\t* 劣势：对于需要精确关键词匹配的查询可能表现不佳。\n",
      "2. **BM25 关键词检索（关键词匹配）**：\n",
      "\t* 优势：对于需要精确关键词匹配的查询可以表现良好。\n",
      "\t* 劣势：可能无法捕获查询和文档的细微差别，适合需要语义理解的查询。\n",
      "3. **融合检索（两者结合）**：\n",
      "\t* 优势：可以捕获查询的语义含义和精确关键词匹配，适合广泛的查询。\n",
      "\t* 劣势：可能需要更多计算资源和复杂实现。\n",
      "\n",
      "**融合检索如何平衡权衡**\n",
      "\n",
      "融合检索通过结合基于向量和 BM25 关键词检索的优势来平衡权衡。通过使用两者的组合，融合检索可以捕获查询的语义含义和精确关键词匹配，从而产生更全面的搜索结果。\n",
      "\n",
      "**何时使用每种方法的建议**\n",
      "\n",
      "1. **基于向量的检索（语义相似性）**：用于需要语义理解的查询，例如询问术语含义或上下文的问题。\n",
      "2. **BM25 关键词检索（关键词匹配）**：用于需要精确关键词匹配的查询，例如搜索特定术语或短语。\n",
      "3. **融合检索（两者结合）**：用于需要语义理解和精确关键词匹配平衡的查询，例如搜索具有细致含义的术语或短语。\n",
      "\n",
      "总之，融合检索提供了基于向量和 BM25 关键词检索的平衡方法，使其适合广泛的查询。虽然它可能需要更多计算资源，但它可以提供更全面和准确的搜索结果。\n"
     ]
    }
   ],
   "source": [
    "# 要处理的 AI 信息文档的路径\n",
    "pdf_path = \"data/AI_Information.pdf\"\n",
    "\n",
    "# 定义涵盖不同类型查询的测试查询来评估融合检索\n",
    "test_queries = [\n",
    "    \"transformer 模型在自然语言处理中的主要应用是什么？\",\n",
    "]\n",
    "\n",
    "# 用于更彻底评估和比较结果的参考答案\n",
    "reference_answers = [\n",
    "    \"Transformer 模型在自然语言处理中的主要应用包括机器翻译、文本生成、情感分析、文本分类、语言建模、问答系统和文本摘要。\",\n",
    "]\n",
    "\n",
    "# 运行评估\n",
    "evaluation_results = evaluate_fusion_retrieval(\n",
    "    pdf_path=pdf_path,\n",
    "    test_queries=test_queries,\n",
    "    reference_answers=reference_answers,\n",
    "    k=5,  # 检索前 5 个文档\n",
    "    alpha=0.5  # 向量和 BM25 分数的平衡权重\n",
    ")\n",
    "\n",
    "# 打印总体分析\n",
    "print(\"\\n=== 总体分析 ===\\n\")\n",
    "print(evaluation_results[\"overall_analysis\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-new-specific-rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}