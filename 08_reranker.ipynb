{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 用于增强 RAG 系统的重新排序\n",
    "\n",
    "本笔记本实现了重新排序技术，以提高 RAG 系统中的检索质量。重新排序在初始检索之后充当第二道筛选步骤，以确保使用最相关的内容来生成响应。\n",
    "\n",
    "## 重新排序的关键概念\n",
    "\n",
    "1.  **初始检索**：使用基本相似性搜索进行第一遍检索（准确性较低但速度较快）。\n",
    "2.  **文档评分**：评估每个检索到的文档与查询的相关性。\n",
    "3.  **重新排序**：根据相关性得分对文档进行排序。\n",
    "4.  **选择**：仅使用最相关的文档进行响应生成。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "导入必要的库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymupdf\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import openai\n",
    "from tqdm import tqdm\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "提取pdf文本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Understanding Artificial Intelligence \n",
      "Chapter 1: Introduction to Artificial Intelligence \n",
      "Artificial intelligence (AI) refers to the ability of a digital computer or computer-controlled robot \n",
      "to perform tasks commonly associated with intelligent beings. The term is frequently applied to \n",
      "the project of developing systems endowed with the intellectual processes characteristic of \n",
      "humans, such as the ability to reason, discover meaning, generalize, or learn from past \n",
      "experience. Over the past f\n"
     ]
    }
   ],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"\n",
    "    提取PDF文件中的文本并打印前`num_chars`个字符。\n",
    "\n",
    "    参数：\n",
    "    pdf_path (str): PDF文件的路径。\n",
    "\n",
    "    返回：\n",
    "    str: 从PDF中提取的文本。\n",
    "\n",
    "    \"\"\"\n",
    "    # 打开PDF文件\n",
    "    mypdf = pymupdf.open(pdf_path)\n",
    "    all_text = \"\"  # 初始化一个空字符串来存储提取的文本\n",
    "\n",
    "    # 迭代PDF中的每个页面\n",
    "    for page_num in range(mypdf.page_count):\n",
    "        page = mypdf[page_num]  # 获取页面\n",
    "        text = page.get_text(\"text\")  # 从页面中提取文本\n",
    "        all_text += text  # 将提取的文本附加到all_text字符串\n",
    "\n",
    "    return all_text  # 返回提取的文本\n",
    "\n",
    "pdf_path = \"data/AI_Information.pdf\"\n",
    "\n",
    "\n",
    "extracted_text = extract_text_from_pdf(pdf_path)\n",
    "\n",
    "print(extracted_text[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "分块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text(text, n, overlap):\n",
    "    \"\"\"\n",
    "    将文本分割为多个块，每个块的大小为n，重叠部分为overlap。\n",
    "    参数：\n",
    "    text: 输入的文本\n",
    "    n: 每个块的大小\n",
    "    overlap: 相邻块之间的重叠部分大小\n",
    "\n",
    "    返回：\n",
    "    文本块列表\n",
    "    \"\"\"\n",
    "    chunks = []  \n",
    "    for i in range(0, len(text), n - overlap):\n",
    "        \n",
    "        chunks.append(text[i:i + n])\n",
    "    \n",
    "    return chunks  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "配置client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = openai.OpenAI(\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\"),  # 如果您没有配置环境变量，请在此处用您的API Key进行替换\n",
    "    base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\"  # 百炼服务的base_url\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "简易向量库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleVectorStore:\n",
    "    \"\"\"\n",
    "    简易的向量存储库。\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.vectors = []\n",
    "        self.texts = []\n",
    "        self.metadata = []\n",
    "    \n",
    "    def add_item(self, text, embedding, metadata=None):\n",
    "        \"\"\"\n",
    "        添加一个新的项到存储库。\n",
    "\n",
    "        参数:\n",
    "        text (str): 文本内容。\n",
    "        embedding (List[float]): 文本的嵌入向量。\n",
    "        metadata (Dict, optional): 与文本相关的元数据。\n",
    "        \"\"\"\n",
    "        self.vectors.append(np.array(embedding))\n",
    "        self.texts.append(text)\n",
    "        self.metadata.append(metadata or {})\n",
    "    \n",
    "    def similarity_search(self, query_embedding, k=5):\n",
    "        \"\"\"\n",
    "        查找与查询嵌入向量最相似的文本。\n",
    "\n",
    "        参数:\n",
    "        query_embedding (List[float]): 查询的嵌入向量。\n",
    "        k (int, optional): 返回最相似的k个结果。\n",
    "\n",
    "        返回:\n",
    "        List[Dict]: 最相似的文本及其相关信息。\n",
    "        \"\"\"\n",
    "        if not self.vectors:\n",
    "            return []\n",
    "        \n",
    "\n",
    "        query_vector = np.array(query_embedding)\n",
    "        \n",
    "\n",
    "        similarities = []\n",
    "        for i, vector in enumerate(self.vectors):\n",
    "            similarity = np.dot(query_vector, vector) / (np.linalg.norm(query_vector) * np.linalg.norm(vector))\n",
    "            similarities.append((i, similarity))\n",
    "        \n",
    "\n",
    "        similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "\n",
    "        results = []\n",
    "        for i in range(min(k, len(similarities))):\n",
    "            idx, score = similarities[i]\n",
    "            results.append({\n",
    "                \"text\": self.texts[idx],\n",
    "                \"metadata\": self.metadata[idx],\n",
    "                \"similarity\": score\n",
    "            })\n",
    "        \n",
    "        return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "向量化\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embeddings_in_batches(text_chunks, model=\"text-embedding-v3\", batch_size_limit=10): # 我改成了官方模型名，你可以换回 \"text-embedding-v3\"\n",
    "    \"\"\"\n",
    "    调用 OpenAI 的 Embedding API 来创建文本列表的嵌入向量，处理批处理大小限制。\n",
    "\n",
    "    参数:\n",
    "    text_chunks (List[str]): 需要创建嵌入的文本字符串列表。\n",
    "    model (str): 使用的嵌入模型。\n",
    "    batch_size_limit (int): API 允许的最大批处理大小。根据错误信息，这里是10。\n",
    "\n",
    "    返回:\n",
    "    List[List[float]]: 所有文本的嵌入向量列表。\n",
    "    \"\"\"\n",
    "    all_embeddings = []\n",
    "    if not text_chunks:\n",
    "        return []\n",
    "\n",
    "    if not isinstance(text_chunks, list): # 确保输入是列表\n",
    "        text_chunks = [text_chunks]\n",
    "\n",
    "    for i in range(0, len(text_chunks), batch_size_limit):\n",
    "        batch = text_chunks[i:i + batch_size_limit]\n",
    "        try:\n",
    "            #print(f\"Processing batch {i//batch_size_limit + 1}, size: {len(batch)}\")\n",
    "            response = client.embeddings.create(\n",
    "                input=batch,\n",
    "                model=model,\n",
    "                encoding_format=\"float\"\n",
    "            )\n",
    "            # 从响应中提取该批次的嵌入向量\n",
    "            batch_embeddings = [item.embedding for item in response.data]\n",
    "            all_embeddings.extend(batch_embeddings)\n",
    "\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing batch starting with chunk: '{batch[0][:50]}...'\")\n",
    "            print(f\"API Error: {e}\")\n",
    "\n",
    "            raise e \n",
    "\n",
    "    return all_embeddings\n",
    "\n",
    "def create_embeddings(text, model=\"text-embedding-v3\"):\n",
    "    \"\"\"\n",
    "    字符串向量化\n",
    "    参数:\n",
    "    text (str): 需要创建嵌入的文本字符串。\n",
    "    model (str): 使用的嵌入模型。\n",
    "\n",
    "    返回:\n",
    "    List[float]: 文本的嵌入向量。\n",
    "    \"\"\"\n",
    "    response = client.embeddings.create(\n",
    "        model=model,\n",
    "        input=text\n",
    "    )\n",
    "\n",
    "    return response.data[0].embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "文本处理流程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_document(pdf_path, chunk_size=1000, chunk_overlap=200):\n",
    "    \"\"\"\n",
    "    处理文本，用于RAG。\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Extracting text from PDF...\")\n",
    "    extracted_text = extract_text_from_pdf(pdf_path)\n",
    "    \n",
    "\n",
    "    print(\"Chunking text...\")\n",
    "    chunks = chunk_text(extracted_text, chunk_size, chunk_overlap)\n",
    "    print(f\"Created {len(chunks)} text chunks\")\n",
    "    \n",
    "\n",
    "    print(\"Creating embeddings for chunks...\")\n",
    "    chunk_embeddings = create_embeddings_in_batches(chunks)\n",
    "    \n",
    "    # Initialize a simple vector store\n",
    "    store = SimpleVectorStore()\n",
    "    \n",
    "    # Add each chunk and its embedding to the vector store\n",
    "    for i, (chunk, embedding) in enumerate(zip(chunks, chunk_embeddings)):\n",
    "        store.add_item(\n",
    "            text=chunk,\n",
    "            embedding=embedding,\n",
    "            metadata={\"index\": i, \"source\": pdf_path}\n",
    "        )\n",
    "    \n",
    "    print(f\"Added {len(chunks)} chunks to the vector store\")\n",
    "    return store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用llm重排序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerank_with_llm(query, results, top_n=3, model=\"qwen-turbo\"):\n",
    "    \"\"\"\n",
    "    使用 LLM 对搜索结果进行重新排序。\n",
    "\n",
    "    参数:\n",
    "    query (str): 用户的查询。\n",
    "    results (List[Dict]): 包含文档文本、元数据和相似度的搜索结果。\n",
    "    top_n (int): 返回的重新排序结果数量。\n",
    "    model (str): 使用的 LLM 模型。\n",
    "\n",
    "    返回:\n",
    "    List[Dict]: 重新排序后的搜索结果。\n",
    "    \"\"\"\n",
    "    print(f\"Reranking {len(results)} documents...\")  \n",
    "    \n",
    "    scored_results = []  \n",
    "    \n",
    "    \n",
    "    system_prompt = \"\"\"You are an expert at evaluating document relevance for search queries.\n",
    "Your task is to rate documents on a scale from 0 to 10 based on how well they answer the given query.\n",
    "\n",
    "Guidelines:\n",
    "- Score 0-2: Document is completely irrelevant\n",
    "- Score 3-5: Document has some relevant information but doesn't directly answer the query\n",
    "- Score 6-8: Document is relevant and partially answers the query\n",
    "- Score 9-10: Document is highly relevant and directly answers the query\n",
    "\n",
    "You MUST respond with ONLY a single integer score between 0 and 10. Do not include ANY other text.\"\"\"\n",
    "    \n",
    "    \n",
    "    for i, result in enumerate(results):\n",
    "        \n",
    "        if i % 5 == 0:\n",
    "            print(f\"Scoring document {i+1}/{len(results)}...\")\n",
    "        \n",
    "        \n",
    "        user_prompt = f\"\"\"Query: {query}\n",
    "\n",
    "Document:\n",
    "{result['text']}\n",
    "\n",
    "Rate this document's relevance to the query on a scale from 0 to 10:\"\"\"\n",
    "        \n",
    "        \n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            temperature=0,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        \n",
    "        score_text = response.choices[0].message.content.strip()\n",
    "        \n",
    "        \n",
    "        score_match = re.search(r'\\b(10|[0-9])\\b', score_text)\n",
    "        if score_match:\n",
    "            score = float(score_match.group(1))\n",
    "        else:\n",
    "            \n",
    "            print(f\"Warning: Could not extract score from response: '{score_text}', using similarity score instead\")\n",
    "            score = result[\"similarity\"] * 10\n",
    "        \n",
    "        \n",
    "        scored_results.append({\n",
    "            \"text\": result[\"text\"],\n",
    "            \"metadata\": result[\"metadata\"],\n",
    "            \"similarity\": result[\"similarity\"],\n",
    "            \"relevance_score\": score\n",
    "        })\n",
    "    \n",
    "    \n",
    "    reranked_results = sorted(scored_results, key=lambda x: x[\"relevance_score\"], reverse=True)\n",
    "    \n",
    "    \n",
    "    return reranked_results[:top_n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "简易的基于关键词的重排"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerank_with_keywords(query, results, top_n=3):\n",
    "    \"\"\"\n",
    "    一个建议的Reranker，它使用关键字匹配来提高与查询相关的文档的排名。\n",
    "    这个函数会给每个文档分配一个分数，分数越高，文档越可能与查询相关。\n",
    "    这个函数会返回与查询最相关的文档。\n",
    "\n",
    "    参数:\n",
    "    query (str): 用户的查询。\n",
    "    results (List[dict]): 包含文档文本、元数据和相似度的列表。\n",
    "    top_n (int): 返回的结果数量。\n",
    "\n",
    "    返回:\n",
    "    List[dict]: 与查询最相关的文档列表。\n",
    "    \"\"\"\n",
    "    \n",
    "    keywords = [word.lower() for word in query.split() if len(word) > 3]\n",
    "    \n",
    "    scored_results = []  \n",
    "    \n",
    "    for result in results:\n",
    "        document_text = result[\"text\"].lower()  \n",
    "        \n",
    "        base_score = result[\"similarity\"] * 0.5\n",
    "        \n",
    "        keyword_score = 0\n",
    "        for keyword in keywords:\n",
    "            if keyword in document_text:\n",
    "                \n",
    "                keyword_score += 0.1\n",
    "                \n",
    "                first_position = document_text.find(keyword)\n",
    "                if first_position < len(document_text) / 4:  \n",
    "                    keyword_score += 0.1\n",
    "                \n",
    "                \n",
    "                frequency = document_text.count(keyword)\n",
    "                keyword_score += min(0.05 * frequency, 0.2)  \n",
    "        \n",
    "        \n",
    "        final_score = base_score + keyword_score\n",
    "        \n",
    "        \n",
    "        scored_results.append({\n",
    "            \"text\": result[\"text\"],\n",
    "            \"metadata\": result[\"metadata\"],\n",
    "            \"similarity\": result[\"similarity\"],\n",
    "            \"relevance_score\": final_score\n",
    "        })\n",
    "    \n",
    "\n",
    "    reranked_results = sorted(scored_results, key=lambda x: x[\"relevance_score\"], reverse=True)\n",
    "    \n",
    "\n",
    "    return reranked_results[:top_n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "生成响应"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(query, context, model=\"qwen3-4b\"):\n",
    "    \"\"\"\n",
    "    生成响应\n",
    "    \"\"\"\n",
    "    \n",
    "    system_prompt = \"You are a helpful AI assistant. Answer the user's question based only on the provided context. If you cannot find the answer in the context, state that you don't have enough information.\"\n",
    "    \n",
    "    \n",
    "    user_prompt = f\"\"\"\n",
    "        Context:\n",
    "        {context}\n",
    "\n",
    "        Question: {query}\n",
    "\n",
    "        Please provide a comprehensive answer based only on the context above.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        temperature=0,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ],\n",
    "        extra_body={\"enable_thinking\": False}\n",
    "    )\n",
    "    \n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "完整RAG流程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_with_reranking(query, vector_store, reranking_method=\"llm\", top_n=3, model=\"qwen-turbo\"):\n",
    "    \n",
    "    query_embedding = create_embeddings(query)\n",
    "    \n",
    "    initial_results = vector_store.similarity_search(query_embedding, k=10)\n",
    "    \n",
    "    if reranking_method == \"llm\":\n",
    "        reranked_results = rerank_with_llm(query, initial_results, top_n=top_n)\n",
    "    elif reranking_method == \"keywords\":\n",
    "        reranked_results = rerank_with_keywords(query, initial_results, top_n=top_n)\n",
    "    else:\n",
    "        \n",
    "        reranked_results = initial_results[:top_n]\n",
    "    \n",
    "    context = \"\\n\\n===\\n\\n\".join([result[\"text\"] for result in reranked_results])\n",
    "    \n",
    "    response = generate_response(query, context, model)\n",
    "    \n",
    "    return {\n",
    "        \"query\": query,\n",
    "        \"reranking_method\": reranking_method,\n",
    "        \"initial_results\": initial_results[:top_n],\n",
    "        \"reranked_results\": reranked_results,\n",
    "        \"context\": context,\n",
    "        \"response\": response\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/val.json') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "query = data[0]['question']\n",
    "\n",
    "reference_answer = data[0]['ideal_answer']\n",
    "\n",
    "pdf_path = \"data/AI_Information.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting text from PDF...\n",
      "Chunking text...\n",
      "Created 42 text chunks\n",
      "Creating embeddings for chunks...\n",
      "Added 42 chunks to the vector store\n",
      "Comparing retrieval methods...\n",
      "\n",
      "=== STANDARD RETRIEVAL ===\n",
      "\n",
      "Query: Does AI have the potential to transform the way we live and work?\n",
      "\n",
      "Response:\n",
      "Yes, AI has the potential to significantly transform the way we live and work, as indicated by the context provided. The transformative impact of AI spans multiple domains, including business, industry, creative fields, and the future of work.\n",
      "\n",
      "In business and industry, AI is already driving improvements in operational efficiency, decision-making, and cost reduction. It enables automation of routine tasks, analysis of large datasets to uncover valuable insights, and optimization of processes such as supply chain management and customer relationship management. AI-powered tools like chatbots and recommendation engines enhance customer engagement and satisfaction, while predictive analytics improves demand forecasting and supply chain resilience.\n",
      "\n",
      "Regarding the future of work, AI presents both challenges and opportunities. While there is concern about job displacement due to automation, particularly in roles involving repetitive or routine tasks, AI also creates new job opportunities in fields such as AI development, data science, and ethics. Human-AI collaboration is emphasized as a key trend, where AI tools can augment human capabilities by handling mundane tasks and offering data-driven insights that support more informed decision-making. Reskilling and upskilling initiatives will be essential to help workers adapt to this changing landscape.\n",
      "\n",
      "AI also holds promise in fostering creativity and innovation. It serves as a tool for generating art, music, and literature, assisting in design processes, and accelerating scientific discovery. Ethical considerations surrounding AI usage in the workplace are highlighted, emphasizing the need for fairness, transparency, and accountability in AI systems, as well as safeguarding worker rights and privacy.\n",
      "\n",
      "Overall, the context underscores that AI has profound potential to reshape nearly every aspect of life and work, necessitating adaptive strategies and ethical frameworks to maximize its benefits while addressing associated challenges.\n",
      "\n",
      "=== LLM-BASED RERANKING ===\n",
      "Reranking 10 documents...\n",
      "Scoring document 1/10...\n",
      "Scoring document 6/10...\n",
      "\n",
      "Query: Does AI have the potential to transform the way we live and work?\n",
      "\n",
      "Response:\n",
      "Yes, AI has the potential to transform the way we live and work. The context highlights several ways in which AI is already impacting our lives and suggests future transformations:\n",
      "\n",
      "1. **Augmentation of Human Capabilities**: AI tools can enhance human productivity by automating mundane tasks and providing insights that support decision-making. This augmentation can lead to more efficient workflows and innovative solutions.\n",
      "\n",
      "2. **New Job Roles**: The development and deployment of AI are creating new job roles in fields such as AI development, data science, AI ethics, and AI training. These roles require specialized skills and expertise, indicating a shift in the labor market towards more tech-oriented positions.\n",
      "\n",
      "3. **Creativity and Innovation**: AI is increasingly being used as a creative tool. It can generate art, music, literature, and assist in design processes, accelerating scientific discovery and fostering innovation.\n",
      "\n",
      "4. **Social Impact**: AI is being utilized to address significant social and environmental challenges, such as climate change, poverty, and healthcare disparities. Initiatives aimed at leveraging AI for positive impact highlight its potential to drive societal progress.\n",
      "\n",
      "5. **Ethical Considerations**: While AI offers transformative possibilities, it also raises ethical concerns related to fairness, transparency, accountability, worker rights, and privacy. Addressing these issues is crucial for responsible AI development.\n",
      "\n",
      "6. **Future Directions and Regulation**: The context emphasizes the need for continued research, responsible development, and thoughtful governance to realize AI's full potential while mitigating risks. International collaborations on standards will be essential as AI becomes more pervasive.\n",
      "\n",
      "Overall, the context underscores AI's capacity to profoundly alter various aspects of life and work, from enhancing productivity and fostering creativity to addressing global challenges and reshaping ethical frameworks.\n",
      "\n",
      "=== KEYWORD-BASED RERANKING ===\n",
      "\n",
      "Query: Does AI have the potential to transform the way we live and work?\n",
      "\n",
      "Response:\n",
      "Yes, AI has the potential to significantly transform the way we live and work. The context highlights several ways in which AI is already impacting and will continue to influence various aspects of life and work:\n",
      "\n",
      "1. **Integration of AI and Robotics**: The combination of AI and robotics allows robots to perform complex tasks, adapt to dynamic environments, and interact more naturally with humans. This integration is being utilized in fields like manufacturing, healthcare, logistics, and exploration, suggesting a profound transformation in how these sectors operate.\n",
      "\n",
      "2. **Enhancing Efficiency and Precision**: In industrial robots, AI improves precision, efficiency, and adaptability, enabling them to work alongside humans in collaborative settings (cobots). This shift not only boosts productivity but also changes traditional workflows by introducing hybrid human-robot teams.\n",
      "\n",
      "3. **Service Robots**: Service robots, powered by AI, assist humans in tasks such as cleaning, delivery, customer service, and healthcare. Their use implies a future where AI-driven automation becomes a common feature in daily life, enhancing convenience and accessibility.\n",
      "\n",
      "4. **Financial Services**: AI is transforming financial services through applications like fraud detection, algorithmic trading, and customer service. By analyzing large datasets and identifying patterns, AI systems can predict market movements and automate processes, fundamentally altering how financial institutions function.\n",
      "\n",
      "5. **Future of Work**: AI raises concerns about job displacement due to automation but also creates new opportunities and transforms existing roles. The need for reskilling and upskilling workers underscores the transformative impact AI will have on employment. Moreover, human-AI collaboration is expected to become increasingly prevalent, with AI tools augmenting human capabilities, automating routine tasks, and providing valuable insights for decision-making.\n",
      "\n",
      "6. **Ethical and Societal Considerations**: The context acknowledges challenges related to transparency, privacy, job displacement, autonomy, and control, indicating that the integration of AI into society will require careful management and governance to ensure its benefits are realized while minimizing risks.\n",
      "\n",
      "In summary, AI has the potential to revolutionize both personal and professional spheres by improving efficiency, creating new opportunities, and reshaping industries. However, this transformation necessitates thoughtful development, regulation, and adaptation to address associated challenges effectively.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vector_store = process_document(pdf_path)\n",
    "\n",
    "\n",
    "query = \"Does AI have the potential to transform the way we live and work?\"\n",
    "\n",
    "\n",
    "print(\"Comparing retrieval methods...\")\n",
    "\n",
    "\n",
    "print(\"\\n=== STANDARD RETRIEVAL ===\")\n",
    "standard_results = rag_with_reranking(query, vector_store, reranking_method=\"none\")\n",
    "print(f\"\\nQuery: {query}\")\n",
    "print(f\"\\nResponse:\\n{standard_results['response']}\")\n",
    "\n",
    "\n",
    "print(\"\\n=== LLM-BASED RERANKING ===\")\n",
    "llm_results = rag_with_reranking(query, vector_store, reranking_method=\"llm\")\n",
    "print(f\"\\nQuery: {query}\")\n",
    "print(f\"\\nResponse:\\n{llm_results['response']}\")\n",
    "\n",
    "\n",
    "print(\"\\n=== KEYWORD-BASED RERANKING ===\")\n",
    "keyword_results = rag_with_reranking(query, vector_store, reranking_method=\"keywords\")\n",
    "print(f\"\\nQuery: {query}\")\n",
    "print(f\"\\nResponse:\\n{keyword_results['response']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_reranking(query, standard_results, reranked_results, reference_answer=None):\n",
    "\n",
    "    system_prompt = \"\"\"You are an expert evaluator of RAG systems.\n",
    "    Compare the retrieved contexts and responses from two different retrieval methods.\n",
    "    Assess which one provides better context and a more accurate, comprehensive answer.\"\"\"\n",
    "    \n",
    "    comparison_text = f\"\"\"Query: {query}\n",
    "\n",
    "    Standard Retrieval Context:\n",
    "    {standard_results['context'][:1000]}... [truncated]\n",
    "\n",
    "    Standard Retrieval Answer:\n",
    "    {standard_results['response']}\n",
    "\n",
    "    Reranked Retrieval Context:\n",
    "    {reranked_results['context'][:1000]}... [truncated]\n",
    "\n",
    "    Reranked Retrieval Answer:\n",
    "    {reranked_results['response']}\"\"\"\n",
    "\n",
    "\n",
    "    if reference_answer:\n",
    "        comparison_text += f\"\"\"\n",
    "        \n",
    "        Reference Answer:\n",
    "        {reference_answer}\"\"\"\n",
    "\n",
    "\n",
    "    user_prompt = f\"\"\"\n",
    "        {comparison_text}\n",
    "\n",
    "        Please evaluate which retrieval method provided:\n",
    "        1. More relevant context\n",
    "        2. More accurate answer\n",
    "        3. More comprehensive answer\n",
    "        4. Better overall performance\n",
    "\n",
    "        Provide a detailed analysis with specific examples.\n",
    "        \"\"\"\n",
    "    \n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"qwen-plus\",\n",
    "        temperature=0,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== EVALUATION RESULTS ===\n",
      "### Evaluation of the Two Retrieval Methods\n",
      "\n",
      "#### **1. More Relevant Context**\n",
      "\n",
      "- **Standard Retrieval Context**:  \n",
      "  The context provided by the standard retrieval method is broad and focuses on several aspects of AI's impact, including automation in finance, job displacement, reskilling/upskilling, human-AI collaboration, and new job roles. While it touches on many important points, it lacks depth in certain areas, such as ethical considerations and creativity, which are crucial for understanding AI's full transformative potential.\n",
      "\n",
      "- **Reranked Retrieval Context**:  \n",
      "  The reranked retrieval context provides more focused information on specific topics like human-AI collaboration, new job roles, ethical considerations, creativity, and innovation. It goes deeper into areas such as AI-generated art, creative tools, and the social impact of AI. This makes it more relevant to the query because it addresses both the practical and philosophical implications of AI transformation comprehensively.\n",
      "\n",
      "**Winner: Reranked Retrieval Context**  \n",
      "The reranked context is more relevant because it includes a broader range of transformative effects (e.g., creativity, ethics) that align well with the query about how AI can \"transform\" life and work.\n",
      "\n",
      "---\n",
      "\n",
      "#### **2. More Accurate Answer**\n",
      "\n",
      "- **Standard Retrieval Answer**:  \n",
      "  The answer from the standard retrieval method is accurate but somewhat repetitive in its structure. It emphasizes business applications, job displacement, reskilling, and human-AI collaboration, which are all valid points. However, it does not delve deeply enough into newer or less conventional areas like AI-driven creativity or ethical challenges beyond fairness and transparency.\n",
      "\n",
      "- **Reranked Retrieval Answer**:  \n",
      "  The reranked answer is equally accurate but adds more nuance by discussing AI’s role in fostering creativity, addressing global challenges (e.g., climate change, poverty), and emphasizing the importance of ethical considerations. It also introduces the idea of international regulation and governance, which adds another layer of accuracy regarding the broader societal implications of AI.\n",
      "\n",
      "**Winner: Reranked Retrieval Answer**  \n",
      "Both answers are factually correct, but the reranked answer incorporates additional dimensions (creativity, global challenges, governance) that make it more precise in responding to the query.\n",
      "\n",
      "---\n",
      "\n",
      "#### **3. More Comprehensive Answer**\n",
      "\n",
      "- **Standard Retrieval Answer**:  \n",
      "  Although this answer covers key areas like automation, job displacement, reskilling, and human-AI collaboration, it lacks coverage of some critical aspects mentioned in the reranked context, such as AI’s role in creativity, innovation, and ethical concerns beyond basic fairness. As a result, the standard answer feels less comprehensive compared to the reranked one.\n",
      "\n",
      "- **Reranked Retrieval Answer**:  \n",
      "  This answer excels in comprehensiveness by covering a wider array of topics, including:\n",
      "  - Augmentation of human capabilities\n",
      "  - Creation of new job roles\n",
      "  - Use of AI as a creative tool\n",
      "  - Social impact and global challenges\n",
      "  - Ethical considerations (fairness, transparency, accountability, worker rights, privacy)\n",
      "  - Future directions and regulation\n",
      "\n",
      "These extra elements provide a richer, more holistic view of AI's transformative potential.\n",
      "\n",
      "**Winner: Reranked Retrieval Answer**  \n",
      "The reranked answer is clearly more comprehensive due to its inclusion of diverse and interconnected aspects of AI's influence on society.\n",
      "\n",
      "---\n",
      "\n",
      "#### **4. Better Overall Performance**\n",
      "\n",
      "To determine overall performance, we consider relevance, accuracy, and comprehensiveness together:\n",
      "\n",
      "- **Standard Retrieval Method**:  \n",
      "  While the standard retrieval method provides an adequate response, it falls short in delivering a sufficiently nuanced or complete picture. Its focus is narrower, missing opportunities to discuss emerging trends like AI-driven creativity and ethical nuances.\n",
      "\n",
      "- **Reranked Retrieval Method**:  \n",
      "  The reranked retrieval method demonstrates superior performance across all metrics:\n",
      "  - **Relevance**: Provides richer, more varied context.\n",
      "  - **Accuracy**: Covers all necessary points while adding valuable insights.\n",
      "  - **Comprehensiveness**: Offers a broader, more inclusive discussion of AI's transformative potential.\n",
      "\n",
      "**Winner: Reranked Retrieval Method**  \n",
      "Overall, the reranked retrieval method outperforms the standard method by offering a more relevant, accurate, and comprehensive response.\n",
      "\n",
      "---\n",
      "\n",
      "### Detailed Analysis with Specific Examples\n",
      "\n",
      "| Metric               | Standard Retrieval Example                                                                 | Reranked Retrieval Example                                                               | Winner          |\n",
      "|----------------------|-------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------|-----------------|\n",
      "| **Relevance**        | Focuses heavily on automation in finance and job displacement, omitting creativity and ethics. | Includes detailed sections on AI creativity, ethical concerns, and global impacts.         | Reranked        |\n",
      "| **Accuracy**         | Correctly mentions automation, reskilling, and collaboration but skips newer areas like AI art.| Accurately discusses AI art, ethical governance, and global challenges like climate change. | Reranked        |\n",
      "| **Comprehensiveness**| Limited to traditional topics; misses creative and regulatory aspects.                        | Explores a wide spectrum, including innovation, ethics, and future governance.              | Reranked        |\n",
      "\n",
      "In conclusion, the **reranked retrieval method** demonstrates better overall performance by providing more relevant, accurate, and comprehensive responses to the query.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "evaluation = evaluate_reranking(\n",
    "    query=query,  \n",
    "    standard_results=standard_results,  \n",
    "    reranked_results=llm_results,  \n",
    "    reference_answer=reference_answer  \n",
    ")\n",
    "\n",
    "\n",
    "print(\"\\n=== EVALUATION RESULTS ===\")\n",
    "print(evaluation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qwen_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
